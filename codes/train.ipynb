{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-06T05:25:24.719724Z",
     "start_time": "2022-03-06T05:25:24.716544Z"
    }
   },
   "outputs": [],
   "source": [
    "# PACS details\n",
    "domains = ['photo', 'art_painting', 'cartoon', 'sketch']\n",
    "classes = ['dog', 'elephant', 'giraffe', 'guitar', 'horse','house', 'person']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-06T05:25:25.298947Z",
     "start_time": "2022-03-06T05:25:24.722460Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.swa_utils import AveragedModel, SWALR\n",
    "\n",
    "import torchvision.datasets as Datasets\n",
    "from torchvision import models\n",
    "from torchvision.datasets import ImageFolder, DatasetFolder\n",
    "\n",
    "from utils import *\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from model.resnet18_selfreg import resnet18\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-06T05:25:25.307448Z",
     "start_time": "2022-03-06T05:25:25.301273Z"
    }
   },
   "outputs": [],
   "source": [
    "##############################\n",
    "# Training Setting\n",
    "##############################\n",
    "\n",
    "# Select model to train\n",
    "# resnet18(pytorch official):'resnet18_classic'\n",
    "# SelfReg : 'resnet18' \n",
    "used_model = 'resnet18'\n",
    "save_name = 'SelfReg_official_test'     # save_dir name\n",
    "                                        # save_path : resnet_18/pacs/{save_name}/\n",
    "dataset ='pacs'        \n",
    "pacs_ver = 'pacs_official_split' \n",
    "number_of_tests = 1\n",
    "gpu_num = 1\n",
    "n_workers = 6\n",
    "\n",
    "##############################\n",
    "# Basic Hyper-parameters\n",
    "##############################\n",
    "\n",
    "is_selfreg = True  # use selfreg?\n",
    "is_idcl = True # use IDCL?\n",
    "\n",
    "epochs = 30\n",
    "batch_size = 128\n",
    "is_pretrained = True  # Use ImageNet pretrain weight ?\n",
    "used_optimizer = 'SGD' # 'Adam' or 'SGD'\n",
    "\n",
    "#Learning rate\n",
    "lr = 4e-3 \n",
    "lr_decay_epoch = [100]\n",
    "lr_decay_gamma = 0.1\n",
    "\n",
    "\n",
    "train_tf, test_tf = get_tf(augment=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-06T05:25:25.366639Z",
     "start_time": "2022-03-06T05:25:25.309290Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n",
      "cuda:1\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    print(\"Using CUDA\")\n",
    "    device = torch.device(\"cuda:{}\".format(gpu_num))\n",
    "print(device)\n",
    "\n",
    "# save settings\n",
    "model_settings = {\n",
    "    \"used_model\": used_model,\n",
    "    \"dataset\": dataset,\n",
    "    \"save_name\": save_name,\n",
    "    \"pacs_ver\": pacs_ver,\n",
    "    \"number_of_tests\": number_of_tests,\n",
    "    \"epochs\": epochs,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"is_pretrained\": is_pretrained,\n",
    "    \"lr\": lr,\n",
    "    \"lr_decay_epoch\": lr_decay_epoch,\n",
    "    \"lr_decay_gamma\": lr_decay_gamma,\n",
    "    \"gpu_num\": gpu_num,\n",
    "}\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-06T05:25:25.405287Z",
     "start_time": "2022-03-06T05:25:25.368640Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "def classic_setting(\n",
    "    test_domain_idx,\n",
    "    domains,\n",
    "    batch_size,\n",
    "    is_pretrained,\n",
    "    train_tf,\n",
    "    test_tf,\n",
    "    used_model,\n",
    "    pacs_ver,\n",
    "    used_optimizer,\n",
    "):\n",
    "\n",
    "    train_set1 = ImageFolder(\n",
    "        root=os.path.join(\n",
    "            \"{}/train\".format(pacs_ver), domains[(test_domain_idx + 1) % len(domains)]\n",
    "        ),\n",
    "        transform=train_tf,\n",
    "    )\n",
    "    train_set2 = ImageFolder(\n",
    "        root=os.path.join(\n",
    "            \"{}/train\".format(pacs_ver), domains[(test_domain_idx + 2) % len(domains)]\n",
    "        ),\n",
    "        transform=train_tf,\n",
    "    )\n",
    "    train_set3 = ImageFolder(\n",
    "        root=os.path.join(\n",
    "            \"{}/train\".format(pacs_ver), domains[(test_domain_idx + 3) % len(domains)]\n",
    "        ),\n",
    "        transform=train_tf,\n",
    "    )\n",
    "\n",
    "    val_set1 = ImageFolder(\n",
    "        root=os.path.join(\n",
    "            \"{}/val\".format(pacs_ver), domains[(test_domain_idx + 1) % len(domains)]\n",
    "        ),\n",
    "        transform=test_tf,\n",
    "    )\n",
    "    val_set2 = ImageFolder(\n",
    "        root=os.path.join(\n",
    "            \"{}/val\".format(pacs_ver), domains[(test_domain_idx + 2) % len(domains)]\n",
    "        ),\n",
    "        transform=test_tf,\n",
    "    )\n",
    "    val_set3 = ImageFolder(\n",
    "        root=os.path.join(\n",
    "            \"{}/val\".format(pacs_ver), domains[(test_domain_idx + 3) % len(domains)]\n",
    "        ),\n",
    "        transform=test_tf,\n",
    "    )\n",
    "\n",
    "    train_set = train_set1 + train_set2 + train_set3\n",
    "    val_set = val_set1 + val_set2 + val_set3\n",
    "    test_set = ImageFolder(\n",
    "        root=os.path.join(\"{}/test\".format(pacs_ver), domains[test_domain_idx]),\n",
    "        transform=test_tf,\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_set, batch_size=batch_size, shuffle=True, num_workers=n_workers\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_set, batch_size=batch_size, shuffle=False, num_workers=n_workers\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        test_set, batch_size=batch_size, shuffle=False, num_workers=n_workers\n",
    "    )\n",
    "\n",
    "    if used_model == \"vgg16\":\n",
    "        model = models.vgg16(pretrained=is_pretrained).cuda()\n",
    "        model.classifier[6].out_features = len(classes)\n",
    "    elif used_model == \"inceptionv3\":\n",
    "        model = models.inception_v3(pretrained=is_pretrained).cuda()\n",
    "        model.AuxLogits.fc.out_features = len(classes)\n",
    "        model.fc.out_features = len(classes)\n",
    "    elif used_model == \"resnet18\":\n",
    "        # load weights pretrained on ImageNet\n",
    "        model = resnet18(pretrained=is_pretrained)\n",
    "        num_ftrs = model.fc.in_features\n",
    "        model.fc = nn.Linear(num_ftrs, len(classes))\n",
    "        model = model.to(device)\n",
    "    elif used_model == \"resnet18_classic\":\n",
    "        model = models.resnet18(pretrained=is_pretrained)\n",
    "        num_ftrs = model.fc.in_features\n",
    "        model.fc = nn.Linear(num_ftrs, len(classes))\n",
    "        model = model.to(device)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    if used_optimizer == \"Adam\":\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    elif used_optimizer == \"SGD\":\n",
    "        optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    swa_model = AveragedModel(model).to(device)\n",
    "    swa_scr = SWALR(optimizer, swa_lr=0.004, anneal_epochs=1)\n",
    "    scheduler = optim.lr_scheduler.MultiStepLR(\n",
    "        optimizer, milestones=lr_decay_epoch, gamma=lr_decay_gamma\n",
    "    )\n",
    "\n",
    "    settings = {\n",
    "        \"train_loaders\": train_loader,\n",
    "        \"val_loaders\": val_loader,\n",
    "        \"optimizer\": optimizer,\n",
    "        \"model\": model,\n",
    "        \"lr_scheduler\": scheduler,\n",
    "        \"swa_model\": swa_model,\n",
    "        \"swa_scr\": swa_scr,\n",
    "    }\n",
    "\n",
    "    return settings, test_loader\n",
    "\n",
    "\n",
    "def IDCL_setting(\n",
    "    test_domain_idx,\n",
    "    domains,\n",
    "    batch_size,\n",
    "    is_pretrained,\n",
    "    train_tf,\n",
    "    test_tf,\n",
    "    used_model,\n",
    "    pacs_ver,\n",
    "    used_optimizer,\n",
    "):\n",
    "\n",
    "    check = 1\n",
    "    train_set = 0\n",
    "    val_set = 0\n",
    "    check_limit = 3\n",
    "\n",
    "    for i in range(4):\n",
    "        if check > check_limit:\n",
    "            break\n",
    "        if i == test_domain_idx:\n",
    "            continue\n",
    "\n",
    "        temp = ImageFolder(\n",
    "            root=os.path.join(\"{}/train\".format(pacs_ver), domains[i]),\n",
    "            transform=train_tf,\n",
    "        )\n",
    "\n",
    "        temp_val = ImageFolder(\n",
    "            root=os.path.join(\"{}/val\".format(pacs_ver), domains[i]), transform=test_tf\n",
    "        )\n",
    "        if check == 1:\n",
    "            train_set = temp\n",
    "            val_set = temp_val\n",
    "        else:\n",
    "            train_set += temp\n",
    "            val_set += temp_val\n",
    "\n",
    "        if check == 1:\n",
    "            train_set_stage1 = train_set\n",
    "            val_set_stage1 = val_set\n",
    "        elif check == 2:\n",
    "            train_set_stage2 = train_set\n",
    "            val_set_stage2 = val_set\n",
    "        elif check == 3:\n",
    "            train_set_stage3 = train_set\n",
    "            val_set_stage3 = val_set\n",
    "\n",
    "        check += 1\n",
    "\n",
    "    test_set = ImageFolder(\n",
    "        root=os.path.join(\"{}/test\".format(pacs_ver), domains[test_domain_idx]),\n",
    "        transform=test_tf,\n",
    "    )\n",
    "\n",
    "    print(\"stage1 (train,val):\", len(train_set_stage1), len(val_set_stage1))\n",
    "    print(\"stage2 (train,val):\", len(train_set_stage2), len(val_set_stage2))\n",
    "    print(\"stage3 (train,val):\", len(train_set_stage3), len(val_set_stage3))\n",
    "    print(\"test :\", len(test_set))\n",
    "\n",
    "    t_loader1 = DataLoader(\n",
    "        train_set_stage1, batch_size=batch_size, shuffle=True, num_workers=6\n",
    "    )\n",
    "    v_loader1 = DataLoader(\n",
    "        val_set_stage1, batch_size=batch_size, shuffle=True, num_workers=6\n",
    "    )\n",
    "\n",
    "    t_loader2 = DataLoader(\n",
    "        train_set_stage2, batch_size=batch_size, shuffle=True, num_workers=6\n",
    "    )\n",
    "    v_loader2 = DataLoader(\n",
    "        val_set_stage2, batch_size=batch_size, shuffle=True, num_workers=6\n",
    "    )\n",
    "\n",
    "    t_loader3 = DataLoader(\n",
    "        train_set_stage3, batch_size=batch_size, shuffle=True, num_workers=6\n",
    "    )\n",
    "    v_loader3 = DataLoader(\n",
    "        val_set_stage3, batch_size=batch_size, shuffle=True, num_workers=6\n",
    "    )\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        test_set, batch_size=batch_size, shuffle=False, num_workers=6\n",
    "    )\n",
    "\n",
    "    if used_model == \"vgg16\":\n",
    "        print(\"vgg16\")\n",
    "        model = models.vgg16(pretrained=is_pretrained).cuda()\n",
    "        model.classifier[6].out_features = 7\n",
    "    elif used_model == \"inceptionv3\":\n",
    "        model = models.inception_v3(pretrained=is_pretrained).cuda()\n",
    "        model.AuxLogits.fc.out_features = 7\n",
    "        model.fc.out_features = 7\n",
    "    elif used_model == \"resnet18\":\n",
    "        model = resnet18(pretrained=is_pretrained)\n",
    "        num_ftrs = model.fc.in_features\n",
    "        model.fc = nn.Linear(num_ftrs, 7)\n",
    "        model = model.to(device)\n",
    "    elif used_model == \"resnet18_classic\":\n",
    "        model = models.resnet18(pretrained=is_pretrained)\n",
    "        num_ftrs = model.fc.in_features\n",
    "        model.fc = nn.Linear(num_ftrs, 7)\n",
    "        model = model.to(device)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    if used_optimizer == \"Adam\":\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    elif used_optimizer == \"SGD\":\n",
    "        optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    swa_model = AveragedModel(model).to(device)\n",
    "    swa_scr = SWALR(optimizer, swa_lr=0.004, anneal_epochs=1)\n",
    "    scheduler = optim.lr_scheduler.MultiStepLR(\n",
    "        optimizer, milestones=lr_decay_epoch, gamma=lr_decay_gamma\n",
    "    )\n",
    "\n",
    "    train_loaders = [t_loader1, t_loader2, t_loader3]\n",
    "    val_loaders = [v_loader1, v_loader2, v_loader3]\n",
    "\n",
    "    settings = {\n",
    "        \"train_loaders\": train_loaders,\n",
    "        \"val_loaders\": val_loaders,\n",
    "        \"optimizer\": optimizer,\n",
    "        \"model\": model,\n",
    "        \"lr_scheduler\": scheduler,\n",
    "        \"swa_model\": swa_model,\n",
    "        \"swa_scr\": swa_scr,\n",
    "    }\n",
    "\n",
    "    return settings, test_loader\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-06T05:31:01.431737Z",
     "start_time": "2022-03-06T05:25:25.407332Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stage1 (train,val): 1499 171\n",
      "stage2 (train,val): 3339 379\n",
      "stage3 (train,val): 5446 616\n",
      "test : 3929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 [128/1499 (9%)],\tAccuracy: 9.4%,  \t Loss: 3.4277\n",
      "Epoch: 1 [256/1499 (17%)],\tAccuracy: 9.4%,  \t Loss: 3.2075\n",
      "Epoch: 1 [384/1499 (26%)],\tAccuracy: 24.2%,  \t Loss: 2.9372\n",
      "Epoch: 1 [512/1499 (34%)],\tAccuracy: 37.5%,  \t Loss: 2.5882\n",
      "Epoch: 1 [640/1499 (43%)],\tAccuracy: 36.7%,  \t Loss: 2.6332\n",
      "Epoch: 1 [768/1499 (51%)],\tAccuracy: 57.8%,  \t Loss: 2.2303\n",
      "Epoch: 1 [896/1499 (60%)],\tAccuracy: 46.1%,  \t Loss: 2.2320\n",
      "Epoch: 1 [1024/1499 (68%)],\tAccuracy: 60.2%,  \t Loss: 2.1070\n",
      "Epoch: 1 [1152/1499 (77%)],\tAccuracy: 77.3%,  \t Loss: 1.7260\n",
      "Epoch: 1 [1280/1499 (85%)],\tAccuracy: 85.2%,  \t Loss: 1.4426\n",
      "Epoch: 1 [1408/1499 (94%)],\tAccuracy: 90.6%,  \t Loss: 1.1760\n",
      "Epoch: 1 [1499/1499 (100%)],\tAccuracy: 90.1%,  \t Loss: 1.2143\n",
      "loss_val: 0.7527423799037933 171\n",
      "acc_val: 160 171\n",
      "Validation ==================================================\n",
      "Avg loss (val): 0.0044\n",
      "Avg acc (val): 0.9357\n",
      "\n",
      "Epoch: 2 [128/1499 (9%)],\tAccuracy: 94.5%,  \t Loss: 1.0053\n",
      "Epoch: 2 [256/1499 (17%)],\tAccuracy: 93.8%,  \t Loss: 0.9160\n",
      "Epoch: 2 [384/1499 (26%)],\tAccuracy: 91.4%,  \t Loss: 0.8044\n",
      "Epoch: 2 [512/1499 (34%)],\tAccuracy: 93.0%,  \t Loss: 0.9273\n",
      "Epoch: 2 [640/1499 (43%)],\tAccuracy: 96.9%,  \t Loss: 0.6449\n",
      "Epoch: 2 [768/1499 (51%)],\tAccuracy: 97.7%,  \t Loss: 0.4749\n",
      "Epoch: 2 [896/1499 (60%)],\tAccuracy: 95.3%,  \t Loss: 0.5279\n",
      "Epoch: 2 [1024/1499 (68%)],\tAccuracy: 95.3%,  \t Loss: 0.7141\n",
      "Epoch: 2 [1152/1499 (77%)],\tAccuracy: 98.4%,  \t Loss: 0.4893\n",
      "Epoch: 2 [1280/1499 (85%)],\tAccuracy: 95.3%,  \t Loss: 0.5146\n",
      "Epoch: 2 [1408/1499 (94%)],\tAccuracy: 96.9%,  \t Loss: 0.4009\n",
      "Epoch: 2 [1499/1499 (100%)],\tAccuracy: 96.7%,  \t Loss: 0.6080\n",
      "loss_val: 0.26306696236133575 171\n",
      "acc_val: 168 171\n",
      "Validation ==================================================\n",
      "Avg loss (val): 0.0015\n",
      "Avg acc (val): 0.9825\n",
      "\n",
      "Epoch: 3 [128/1499 (9%)],\tAccuracy: 97.7%,  \t Loss: 0.3630\n",
      "Epoch: 3 [256/1499 (17%)],\tAccuracy: 97.7%,  \t Loss: 0.3330\n",
      "Epoch: 3 [384/1499 (26%)],\tAccuracy: 100.0%,  \t Loss: 0.3192\n",
      "Epoch: 3 [512/1499 (34%)],\tAccuracy: 96.1%,  \t Loss: 0.3407\n",
      "Epoch: 3 [640/1499 (43%)],\tAccuracy: 96.9%,  \t Loss: 0.3639\n",
      "Epoch: 3 [768/1499 (51%)],\tAccuracy: 99.2%,  \t Loss: 0.4006\n",
      "Epoch: 3 [896/1499 (60%)],\tAccuracy: 98.4%,  \t Loss: 0.2466\n",
      "Epoch: 3 [1024/1499 (68%)],\tAccuracy: 99.2%,  \t Loss: 0.2424\n",
      "Epoch: 3 [1152/1499 (77%)],\tAccuracy: 98.4%,  \t Loss: 0.2880\n",
      "Epoch: 3 [1280/1499 (85%)],\tAccuracy: 99.2%,  \t Loss: 0.1883\n",
      "Epoch: 3 [1408/1499 (94%)],\tAccuracy: 97.7%,  \t Loss: 0.3497\n",
      "Epoch: 3 [1499/1499 (100%)],\tAccuracy: 97.8%,  \t Loss: 0.2795\n",
      "loss_val: 0.18797490000724792 171\n",
      "acc_val: 169 171\n",
      "Validation ==================================================\n",
      "Avg loss (val): 0.0011\n",
      "Avg acc (val): 0.9883\n",
      "\n",
      "Epoch: 4 [128/1499 (9%)],\tAccuracy: 99.2%,  \t Loss: 0.1701\n",
      "Epoch: 4 [256/1499 (17%)],\tAccuracy: 98.4%,  \t Loss: 0.2870\n",
      "Epoch: 4 [384/1499 (26%)],\tAccuracy: 99.2%,  \t Loss: 0.1532\n",
      "Epoch: 4 [512/1499 (34%)],\tAccuracy: 100.0%,  \t Loss: 0.1393\n",
      "Epoch: 4 [640/1499 (43%)],\tAccuracy: 97.7%,  \t Loss: 0.2013\n",
      "Epoch: 4 [768/1499 (51%)],\tAccuracy: 96.9%,  \t Loss: 0.3420\n",
      "Epoch: 4 [896/1499 (60%)],\tAccuracy: 98.4%,  \t Loss: 0.1926\n",
      "Epoch: 4 [1024/1499 (68%)],\tAccuracy: 98.4%,  \t Loss: 0.1972\n",
      "Epoch: 4 [1152/1499 (77%)],\tAccuracy: 97.7%,  \t Loss: 0.2606\n",
      "Epoch: 4 [1280/1499 (85%)],\tAccuracy: 98.4%,  \t Loss: 0.1732\n",
      "Epoch: 4 [1408/1499 (94%)],\tAccuracy: 96.9%,  \t Loss: 0.2242\n",
      "Epoch: 4 [1499/1499 (100%)],\tAccuracy: 97.8%,  \t Loss: 0.2502\n",
      "loss_val: 0.1270812749862671 171\n",
      "acc_val: 170 171\n",
      "Validation ==================================================\n",
      "Avg loss (val): 0.0007\n",
      "Avg acc (val): 0.9942\n",
      "\n",
      "Epoch: 5 [128/1499 (9%)],\tAccuracy: 98.4%,  \t Loss: 0.1507\n",
      "Epoch: 5 [256/1499 (17%)],\tAccuracy: 100.0%,  \t Loss: 0.1270\n",
      "Epoch: 5 [384/1499 (26%)],\tAccuracy: 97.7%,  \t Loss: 0.2211\n",
      "Epoch: 5 [512/1499 (34%)],\tAccuracy: 98.4%,  \t Loss: 0.1669\n",
      "Epoch: 5 [640/1499 (43%)],\tAccuracy: 98.4%,  \t Loss: 0.2343\n",
      "Epoch: 5 [768/1499 (51%)],\tAccuracy: 97.7%,  \t Loss: 0.2534\n",
      "Epoch: 5 [896/1499 (60%)],\tAccuracy: 100.0%,  \t Loss: 0.0786\n",
      "Epoch: 5 [1024/1499 (68%)],\tAccuracy: 99.2%,  \t Loss: 0.2537\n",
      "Epoch: 5 [1152/1499 (77%)],\tAccuracy: 100.0%,  \t Loss: 0.1275\n",
      "Epoch: 5 [1280/1499 (85%)],\tAccuracy: 99.2%,  \t Loss: 0.1353\n",
      "Epoch: 5 [1408/1499 (94%)],\tAccuracy: 99.2%,  \t Loss: 0.1177\n",
      "Epoch: 5 [1499/1499 (100%)],\tAccuracy: 100.0%,  \t Loss: 0.0776\n",
      "loss_val: 0.11499607935547829 171\n",
      "acc_val: 170 171\n",
      "Validation ==================================================\n",
      "Avg loss (val): 0.0007\n",
      "Avg acc (val): 0.9942\n",
      "\n",
      "Epoch: 6 [128/3339 (4%)],\tAccuracy: 81.2%,  \t Loss: 3.1356\n",
      "Epoch: 6 [256/3339 (8%)],\tAccuracy: 79.7%,  \t Loss: 2.4813\n",
      "Epoch: 6 [384/3339 (12%)],\tAccuracy: 84.4%,  \t Loss: 1.7686\n",
      "Epoch: 6 [512/3339 (15%)],\tAccuracy: 83.6%,  \t Loss: 1.4984\n",
      "Epoch: 6 [640/3339 (19%)],\tAccuracy: 85.9%,  \t Loss: 1.1478\n",
      "Epoch: 6 [768/3339 (23%)],\tAccuracy: 83.6%,  \t Loss: 1.5172\n",
      "Epoch: 6 [896/3339 (27%)],\tAccuracy: 81.2%,  \t Loss: 1.5878\n",
      "Epoch: 6 [1024/3339 (31%)],\tAccuracy: 87.5%,  \t Loss: 1.6239\n",
      "Epoch: 6 [1152/3339 (35%)],\tAccuracy: 92.2%,  \t Loss: 1.1968\n",
      "Epoch: 6 [1280/3339 (38%)],\tAccuracy: 89.8%,  \t Loss: 1.4399\n",
      "Epoch: 6 [1408/3339 (42%)],\tAccuracy: 89.1%,  \t Loss: 1.6593\n",
      "Epoch: 6 [1536/3339 (46%)],\tAccuracy: 85.9%,  \t Loss: 1.5307\n",
      "Epoch: 6 [1664/3339 (50%)],\tAccuracy: 82.8%,  \t Loss: 1.4902\n",
      "Epoch: 6 [1792/3339 (54%)],\tAccuracy: 94.5%,  \t Loss: 1.0973\n",
      "Epoch: 6 [1920/3339 (58%)],\tAccuracy: 91.4%,  \t Loss: 1.3482\n",
      "Epoch: 6 [2048/3339 (61%)],\tAccuracy: 87.5%,  \t Loss: 1.2598\n",
      "Epoch: 6 [2176/3339 (65%)],\tAccuracy: 93.8%,  \t Loss: 1.0942\n",
      "Epoch: 6 [2304/3339 (69%)],\tAccuracy: 87.5%,  \t Loss: 1.2215\n",
      "Epoch: 6 [2432/3339 (73%)],\tAccuracy: 81.2%,  \t Loss: 1.3745\n",
      "Epoch: 6 [2560/3339 (77%)],\tAccuracy: 83.6%,  \t Loss: 1.2858\n",
      "Epoch: 6 [2688/3339 (81%)],\tAccuracy: 90.6%,  \t Loss: 1.0235\n",
      "Epoch: 6 [2816/3339 (84%)],\tAccuracy: 91.4%,  \t Loss: 1.1071\n",
      "Epoch: 6 [2944/3339 (88%)],\tAccuracy: 89.8%,  \t Loss: 1.3005\n",
      "Epoch: 6 [3072/3339 (92%)],\tAccuracy: 96.9%,  \t Loss: 0.9473\n",
      "Epoch: 6 [3200/3339 (96%)],\tAccuracy: 89.8%,  \t Loss: 1.0647\n",
      "Epoch: 6 [3328/3339 (100%)],\tAccuracy: 93.8%,  \t Loss: 0.8821\n",
      "Epoch: 6 [3339/3339 (100%)],\tAccuracy: 100.0%,  \t Loss: 0.5654\n",
      "loss_val: 1.4931815266609192 379\n",
      "acc_val: 338 379\n",
      "Validation ==================================================\n",
      "Avg loss (val): 0.0039\n",
      "Avg acc (val): 0.8918\n",
      "\n",
      "Epoch: 7 [128/3339 (4%)],\tAccuracy: 95.3%,  \t Loss: 0.9551\n",
      "Epoch: 7 [256/3339 (8%)],\tAccuracy: 89.8%,  \t Loss: 1.0633\n",
      "Epoch: 7 [384/3339 (12%)],\tAccuracy: 89.1%,  \t Loss: 1.0559\n",
      "Epoch: 7 [512/3339 (15%)],\tAccuracy: 94.5%,  \t Loss: 0.8291\n",
      "Epoch: 7 [640/3339 (19%)],\tAccuracy: 96.1%,  \t Loss: 0.7805\n",
      "Epoch: 7 [768/3339 (23%)],\tAccuracy: 90.6%,  \t Loss: 0.8644\n",
      "Epoch: 7 [896/3339 (27%)],\tAccuracy: 95.3%,  \t Loss: 0.6236\n",
      "Epoch: 7 [1024/3339 (31%)],\tAccuracy: 93.0%,  \t Loss: 0.6979\n",
      "Epoch: 7 [1152/3339 (35%)],\tAccuracy: 93.8%,  \t Loss: 0.7960\n",
      "Epoch: 7 [1280/3339 (38%)],\tAccuracy: 93.8%,  \t Loss: 0.7466\n",
      "Epoch: 7 [1408/3339 (42%)],\tAccuracy: 95.3%,  \t Loss: 0.7897\n",
      "Epoch: 7 [1536/3339 (46%)],\tAccuracy: 94.5%,  \t Loss: 0.6350\n",
      "Epoch: 7 [1664/3339 (50%)],\tAccuracy: 94.5%,  \t Loss: 0.6835\n",
      "Epoch: 7 [1792/3339 (54%)],\tAccuracy: 92.2%,  \t Loss: 0.8755\n",
      "Epoch: 7 [1920/3339 (58%)],\tAccuracy: 93.8%,  \t Loss: 0.6879\n",
      "Epoch: 7 [2048/3339 (61%)],\tAccuracy: 96.1%,  \t Loss: 0.5928\n",
      "Epoch: 7 [2176/3339 (65%)],\tAccuracy: 94.5%,  \t Loss: 0.7947\n",
      "Epoch: 7 [2304/3339 (69%)],\tAccuracy: 96.1%,  \t Loss: 0.6004\n",
      "Epoch: 7 [2432/3339 (73%)],\tAccuracy: 93.8%,  \t Loss: 0.6480\n",
      "Epoch: 7 [2560/3339 (77%)],\tAccuracy: 96.1%,  \t Loss: 0.5087\n",
      "Epoch: 7 [2688/3339 (81%)],\tAccuracy: 95.3%,  \t Loss: 0.6540\n",
      "Epoch: 7 [2816/3339 (84%)],\tAccuracy: 96.1%,  \t Loss: 0.6908\n",
      "Epoch: 7 [2944/3339 (88%)],\tAccuracy: 96.1%,  \t Loss: 0.6158\n",
      "Epoch: 7 [3072/3339 (92%)],\tAccuracy: 96.1%,  \t Loss: 0.5863\n",
      "Epoch: 7 [3200/3339 (96%)],\tAccuracy: 93.8%,  \t Loss: 0.6239\n",
      "Epoch: 7 [3328/3339 (100%)],\tAccuracy: 96.9%,  \t Loss: 0.3929\n",
      "Epoch: 7 [3339/3339 (100%)],\tAccuracy: 90.9%,  \t Loss: 1.2446\n",
      "loss_val: 0.9817832112312317 379\n",
      "acc_val: 347 379\n",
      "Validation ==================================================\n",
      "Avg loss (val): 0.0026\n",
      "Avg acc (val): 0.9156\n",
      "\n",
      "Epoch: 8 [128/3339 (4%)],\tAccuracy: 96.1%,  \t Loss: 0.5931\n",
      "Epoch: 8 [256/3339 (8%)],\tAccuracy: 91.4%,  \t Loss: 0.6732\n",
      "Epoch: 8 [384/3339 (12%)],\tAccuracy: 93.8%,  \t Loss: 0.7413\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 [512/3339 (15%)],\tAccuracy: 95.3%,  \t Loss: 0.5806\n",
      "Epoch: 8 [640/3339 (19%)],\tAccuracy: 95.3%,  \t Loss: 0.4947\n",
      "Epoch: 8 [768/3339 (23%)],\tAccuracy: 94.5%,  \t Loss: 0.5162\n",
      "Epoch: 8 [896/3339 (27%)],\tAccuracy: 96.1%,  \t Loss: 0.5768\n",
      "Epoch: 8 [1024/3339 (31%)],\tAccuracy: 96.1%,  \t Loss: 0.5725\n",
      "Epoch: 8 [1152/3339 (35%)],\tAccuracy: 96.1%,  \t Loss: 0.5072\n",
      "Epoch: 8 [1280/3339 (38%)],\tAccuracy: 95.3%,  \t Loss: 0.4586\n",
      "Epoch: 8 [1408/3339 (42%)],\tAccuracy: 93.0%,  \t Loss: 0.5824\n",
      "Epoch: 8 [1536/3339 (46%)],\tAccuracy: 97.7%,  \t Loss: 0.4179\n",
      "Epoch: 8 [1664/3339 (50%)],\tAccuracy: 96.1%,  \t Loss: 0.4768\n",
      "Epoch: 8 [1792/3339 (54%)],\tAccuracy: 94.5%,  \t Loss: 0.6661\n",
      "Epoch: 8 [1920/3339 (58%)],\tAccuracy: 96.1%,  \t Loss: 0.4735\n",
      "Epoch: 8 [2048/3339 (61%)],\tAccuracy: 93.0%,  \t Loss: 0.5217\n",
      "Epoch: 8 [2176/3339 (65%)],\tAccuracy: 96.9%,  \t Loss: 0.4008\n",
      "Epoch: 8 [2304/3339 (69%)],\tAccuracy: 98.4%,  \t Loss: 0.4477\n",
      "Epoch: 8 [2432/3339 (73%)],\tAccuracy: 95.3%,  \t Loss: 0.4420\n",
      "Epoch: 8 [2560/3339 (77%)],\tAccuracy: 95.3%,  \t Loss: 0.5117\n",
      "Epoch: 8 [2688/3339 (81%)],\tAccuracy: 95.3%,  \t Loss: 0.4955\n",
      "Epoch: 8 [2816/3339 (84%)],\tAccuracy: 93.8%,  \t Loss: 0.5481\n",
      "Epoch: 8 [2944/3339 (88%)],\tAccuracy: 96.9%,  \t Loss: 0.4801\n",
      "Epoch: 8 [3072/3339 (92%)],\tAccuracy: 97.7%,  \t Loss: 0.4235\n",
      "Epoch: 8 [3200/3339 (96%)],\tAccuracy: 95.3%,  \t Loss: 0.5110\n",
      "Epoch: 8 [3328/3339 (100%)],\tAccuracy: 97.7%,  \t Loss: 0.3764\n",
      "Epoch: 8 [3339/3339 (100%)],\tAccuracy: 81.8%,  \t Loss: 0.8419\n",
      "loss_val: 0.8224096596240997 379\n",
      "acc_val: 354 379\n",
      "Validation ==================================================\n",
      "Avg loss (val): 0.0022\n",
      "Avg acc (val): 0.9340\n",
      "\n",
      "Epoch: 9 [128/3339 (4%)],\tAccuracy: 93.0%,  \t Loss: 0.6307\n",
      "Epoch: 9 [256/3339 (8%)],\tAccuracy: 95.3%,  \t Loss: 0.4323\n",
      "Epoch: 9 [384/3339 (12%)],\tAccuracy: 96.9%,  \t Loss: 0.3607\n",
      "Epoch: 9 [512/3339 (15%)],\tAccuracy: 94.5%,  \t Loss: 0.4984\n",
      "Epoch: 9 [640/3339 (19%)],\tAccuracy: 95.3%,  \t Loss: 0.5100\n",
      "Epoch: 9 [768/3339 (23%)],\tAccuracy: 97.7%,  \t Loss: 0.4809\n",
      "Epoch: 9 [896/3339 (27%)],\tAccuracy: 96.9%,  \t Loss: 0.3363\n",
      "Epoch: 9 [1024/3339 (31%)],\tAccuracy: 96.9%,  \t Loss: 0.3831\n",
      "Epoch: 9 [1152/3339 (35%)],\tAccuracy: 96.1%,  \t Loss: 0.4341\n",
      "Epoch: 9 [1280/3339 (38%)],\tAccuracy: 99.2%,  \t Loss: 0.3562\n",
      "Epoch: 9 [1408/3339 (42%)],\tAccuracy: 94.5%,  \t Loss: 0.5059\n",
      "Epoch: 9 [1536/3339 (46%)],\tAccuracy: 98.4%,  \t Loss: 0.4179\n",
      "Epoch: 9 [1664/3339 (50%)],\tAccuracy: 94.5%,  \t Loss: 0.4172\n",
      "Epoch: 9 [1792/3339 (54%)],\tAccuracy: 96.1%,  \t Loss: 0.5346\n",
      "Epoch: 9 [1920/3339 (58%)],\tAccuracy: 96.9%,  \t Loss: 0.4835\n",
      "Epoch: 9 [2048/3339 (61%)],\tAccuracy: 97.7%,  \t Loss: 0.4062\n",
      "Epoch: 9 [2176/3339 (65%)],\tAccuracy: 97.7%,  \t Loss: 0.4167\n",
      "Epoch: 9 [2304/3339 (69%)],\tAccuracy: 96.9%,  \t Loss: 0.5285\n",
      "Epoch: 9 [2432/3339 (73%)],\tAccuracy: 96.1%,  \t Loss: 0.3217\n",
      "Epoch: 9 [2560/3339 (77%)],\tAccuracy: 98.4%,  \t Loss: 0.4049\n",
      "Epoch: 9 [2688/3339 (81%)],\tAccuracy: 98.4%,  \t Loss: 0.2721\n",
      "Epoch: 9 [2816/3339 (84%)],\tAccuracy: 96.9%,  \t Loss: 0.4210\n",
      "Epoch: 9 [2944/3339 (88%)],\tAccuracy: 97.7%,  \t Loss: 0.3833\n",
      "Epoch: 9 [3072/3339 (92%)],\tAccuracy: 95.3%,  \t Loss: 0.5411\n",
      "Epoch: 9 [3200/3339 (96%)],\tAccuracy: 97.7%,  \t Loss: 0.3984\n",
      "Epoch: 9 [3328/3339 (100%)],\tAccuracy: 96.9%,  \t Loss: 0.4214\n",
      "Epoch: 9 [3339/3339 (100%)],\tAccuracy: 90.9%,  \t Loss: 0.4941\n",
      "loss_val: 0.6727780997753143 379\n",
      "acc_val: 352 379\n",
      "Validation ==================================================\n",
      "Avg loss (val): 0.0018\n",
      "Avg acc (val): 0.9288\n",
      "\n",
      "Epoch: 10 [128/3339 (4%)],\tAccuracy: 95.3%,  \t Loss: 0.3737\n",
      "Epoch: 10 [256/3339 (8%)],\tAccuracy: 96.9%,  \t Loss: 0.3573\n",
      "Epoch: 10 [384/3339 (12%)],\tAccuracy: 97.7%,  \t Loss: 0.2597\n",
      "Epoch: 10 [512/3339 (15%)],\tAccuracy: 94.5%,  \t Loss: 0.5161\n",
      "Epoch: 10 [640/3339 (19%)],\tAccuracy: 97.7%,  \t Loss: 0.3595\n",
      "Epoch: 10 [768/3339 (23%)],\tAccuracy: 100.0%,  \t Loss: 0.2729\n",
      "Epoch: 10 [896/3339 (27%)],\tAccuracy: 97.7%,  \t Loss: 0.3429\n",
      "Epoch: 10 [1024/3339 (31%)],\tAccuracy: 96.9%,  \t Loss: 0.4379\n",
      "Epoch: 10 [1152/3339 (35%)],\tAccuracy: 97.7%,  \t Loss: 0.3043\n",
      "Epoch: 10 [1280/3339 (38%)],\tAccuracy: 98.4%,  \t Loss: 0.2157\n",
      "Epoch: 10 [1408/3339 (42%)],\tAccuracy: 96.9%,  \t Loss: 0.3939\n",
      "Epoch: 10 [1536/3339 (46%)],\tAccuracy: 98.4%,  \t Loss: 0.3716\n",
      "Epoch: 10 [1664/3339 (50%)],\tAccuracy: 96.9%,  \t Loss: 0.3898\n",
      "Epoch: 10 [1792/3339 (54%)],\tAccuracy: 99.2%,  \t Loss: 0.2565\n",
      "Epoch: 10 [1920/3339 (58%)],\tAccuracy: 97.7%,  \t Loss: 0.3964\n",
      "Epoch: 10 [2048/3339 (61%)],\tAccuracy: 97.7%,  \t Loss: 0.3274\n",
      "Epoch: 10 [2176/3339 (65%)],\tAccuracy: 97.7%,  \t Loss: 0.3186\n",
      "Epoch: 10 [2304/3339 (69%)],\tAccuracy: 96.9%,  \t Loss: 0.3501\n",
      "Epoch: 10 [2432/3339 (73%)],\tAccuracy: 99.2%,  \t Loss: 0.3311\n",
      "Epoch: 10 [2560/3339 (77%)],\tAccuracy: 96.9%,  \t Loss: 0.3025\n",
      "Epoch: 10 [2688/3339 (81%)],\tAccuracy: 98.4%,  \t Loss: 0.2498\n",
      "Epoch: 10 [2816/3339 (84%)],\tAccuracy: 98.4%,  \t Loss: 0.2457\n",
      "Epoch: 10 [2944/3339 (88%)],\tAccuracy: 97.7%,  \t Loss: 0.2306\n",
      "Epoch: 10 [3072/3339 (92%)],\tAccuracy: 98.4%,  \t Loss: 0.3111\n",
      "Epoch: 10 [3200/3339 (96%)],\tAccuracy: 98.4%,  \t Loss: 0.3168\n",
      "Epoch: 10 [3328/3339 (100%)],\tAccuracy: 99.2%,  \t Loss: 0.2446\n",
      "Epoch: 10 [3339/3339 (100%)],\tAccuracy: 81.8%,  \t Loss: 1.0193\n",
      "loss_val: 0.6976584792137146 379\n",
      "acc_val: 356 379\n",
      "Validation ==================================================\n",
      "Avg loss (val): 0.0018\n",
      "Avg acc (val): 0.9393\n",
      "\n",
      "Epoch: 11 [128/5446 (2%)],\tAccuracy: 81.2%,  \t Loss: 1.3863\n",
      "Epoch: 11 [256/5446 (5%)],\tAccuracy: 85.2%,  \t Loss: 1.2936\n",
      "Epoch: 11 [384/5446 (7%)],\tAccuracy: 85.2%,  \t Loss: 1.6851\n",
      "Epoch: 11 [512/5446 (9%)],\tAccuracy: 93.8%,  \t Loss: 0.8123\n",
      "Epoch: 11 [640/5446 (12%)],\tAccuracy: 88.3%,  \t Loss: 0.9916\n",
      "Epoch: 11 [768/5446 (14%)],\tAccuracy: 83.6%,  \t Loss: 1.1774\n",
      "Epoch: 11 [896/5446 (16%)],\tAccuracy: 89.1%,  \t Loss: 0.8993\n",
      "Epoch: 11 [1024/5446 (19%)],\tAccuracy: 90.6%,  \t Loss: 0.9513\n",
      "Epoch: 11 [1152/5446 (21%)],\tAccuracy: 96.1%,  \t Loss: 0.7763\n",
      "Epoch: 11 [1280/5446 (24%)],\tAccuracy: 89.1%,  \t Loss: 0.8000\n",
      "Epoch: 11 [1408/5446 (26%)],\tAccuracy: 89.1%,  \t Loss: 0.9822\n",
      "Epoch: 11 [1536/5446 (28%)],\tAccuracy: 88.3%,  \t Loss: 0.9311\n",
      "Epoch: 11 [1664/5446 (31%)],\tAccuracy: 91.4%,  \t Loss: 0.8843\n",
      "Epoch: 11 [1792/5446 (33%)],\tAccuracy: 88.3%,  \t Loss: 0.9901\n",
      "Epoch: 11 [1920/5446 (35%)],\tAccuracy: 87.5%,  \t Loss: 1.1134\n",
      "Epoch: 11 [2048/5446 (38%)],\tAccuracy: 91.4%,  \t Loss: 0.9124\n",
      "Epoch: 11 [2176/5446 (40%)],\tAccuracy: 86.7%,  \t Loss: 1.0399\n",
      "Epoch: 11 [2304/5446 (42%)],\tAccuracy: 92.2%,  \t Loss: 0.9029\n",
      "Epoch: 11 [2432/5446 (45%)],\tAccuracy: 87.5%,  \t Loss: 1.1040\n",
      "Epoch: 11 [2560/5446 (47%)],\tAccuracy: 89.8%,  \t Loss: 0.9316\n",
      "Epoch: 11 [2688/5446 (49%)],\tAccuracy: 93.0%,  \t Loss: 0.8382\n",
      "Epoch: 11 [2816/5446 (52%)],\tAccuracy: 93.0%,  \t Loss: 0.9618\n",
      "Epoch: 11 [2944/5446 (54%)],\tAccuracy: 95.3%,  \t Loss: 0.7421\n",
      "Epoch: 11 [3072/5446 (56%)],\tAccuracy: 94.5%,  \t Loss: 0.9072\n",
      "Epoch: 11 [3200/5446 (59%)],\tAccuracy: 95.3%,  \t Loss: 0.7920\n",
      "Epoch: 11 [3328/5446 (61%)],\tAccuracy: 93.0%,  \t Loss: 0.8247\n",
      "Epoch: 11 [3456/5446 (63%)],\tAccuracy: 89.1%,  \t Loss: 0.9606\n",
      "Epoch: 11 [3584/5446 (66%)],\tAccuracy: 89.1%,  \t Loss: 1.0739\n",
      "Epoch: 11 [3712/5446 (68%)],\tAccuracy: 91.4%,  \t Loss: 0.8009\n",
      "Epoch: 11 [3840/5446 (71%)],\tAccuracy: 95.3%,  \t Loss: 0.8043\n",
      "Epoch: 11 [3968/5446 (73%)],\tAccuracy: 89.8%,  \t Loss: 0.9128\n",
      "Epoch: 11 [4096/5446 (75%)],\tAccuracy: 91.4%,  \t Loss: 0.8244\n",
      "Epoch: 11 [4224/5446 (78%)],\tAccuracy: 91.4%,  \t Loss: 0.7957\n",
      "Epoch: 11 [4352/5446 (80%)],\tAccuracy: 91.4%,  \t Loss: 0.8143\n",
      "Epoch: 11 [4480/5446 (82%)],\tAccuracy: 96.1%,  \t Loss: 0.6765\n",
      "Epoch: 11 [4608/5446 (85%)],\tAccuracy: 93.8%,  \t Loss: 0.8238\n",
      "Epoch: 11 [4736/5446 (87%)],\tAccuracy: 94.5%,  \t Loss: 0.6547\n",
      "Epoch: 11 [4864/5446 (89%)],\tAccuracy: 96.1%,  \t Loss: 0.5604\n",
      "Epoch: 11 [4992/5446 (92%)],\tAccuracy: 93.0%,  \t Loss: 0.8034\n",
      "Epoch: 11 [5120/5446 (94%)],\tAccuracy: 93.8%,  \t Loss: 0.7006\n",
      "Epoch: 11 [5248/5446 (96%)],\tAccuracy: 94.5%,  \t Loss: 0.6475\n",
      "Epoch: 11 [5376/5446 (99%)],\tAccuracy: 95.3%,  \t Loss: 0.6738\n",
      "Epoch: 11 [5446/5446 (100%)],\tAccuracy: 92.9%,  \t Loss: 0.7891\n",
      "loss_val: 1.6915773451328278 616\n",
      "acc_val: 574 616\n",
      "Validation ==================================================\n",
      "Avg loss (val): 0.0027\n",
      "Avg acc (val): 0.9318\n",
      "\n",
      "Epoch: 12 [128/5446 (2%)],\tAccuracy: 92.2%,  \t Loss: 0.7400\n",
      "Epoch: 12 [256/5446 (5%)],\tAccuracy: 94.5%,  \t Loss: 0.5949\n",
      "Epoch: 12 [384/5446 (7%)],\tAccuracy: 95.3%,  \t Loss: 0.5454\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12 [512/5446 (9%)],\tAccuracy: 94.5%,  \t Loss: 0.6204\n",
      "Epoch: 12 [640/5446 (12%)],\tAccuracy: 95.3%,  \t Loss: 0.6492\n",
      "Epoch: 12 [768/5446 (14%)],\tAccuracy: 93.8%,  \t Loss: 0.5862\n",
      "Epoch: 12 [896/5446 (16%)],\tAccuracy: 91.4%,  \t Loss: 0.7624\n",
      "Epoch: 12 [1024/5446 (19%)],\tAccuracy: 93.8%,  \t Loss: 0.7025\n",
      "Epoch: 12 [1152/5446 (21%)],\tAccuracy: 96.9%,  \t Loss: 0.4881\n",
      "Epoch: 12 [1280/5446 (24%)],\tAccuracy: 95.3%,  \t Loss: 0.5873\n",
      "Epoch: 12 [1408/5446 (26%)],\tAccuracy: 93.8%,  \t Loss: 0.7397\n",
      "Epoch: 12 [1536/5446 (28%)],\tAccuracy: 92.2%,  \t Loss: 0.7800\n",
      "Epoch: 12 [1664/5446 (31%)],\tAccuracy: 96.1%,  \t Loss: 0.5298\n",
      "Epoch: 12 [1792/5446 (33%)],\tAccuracy: 95.3%,  \t Loss: 0.4646\n",
      "Epoch: 12 [1920/5446 (35%)],\tAccuracy: 96.1%,  \t Loss: 0.5923\n",
      "Epoch: 12 [2048/5446 (38%)],\tAccuracy: 93.8%,  \t Loss: 0.5852\n",
      "Epoch: 12 [2176/5446 (40%)],\tAccuracy: 95.3%,  \t Loss: 0.5916\n",
      "Epoch: 12 [2304/5446 (42%)],\tAccuracy: 96.1%,  \t Loss: 0.4959\n",
      "Epoch: 12 [2432/5446 (45%)],\tAccuracy: 97.7%,  \t Loss: 0.4676\n",
      "Epoch: 12 [2560/5446 (47%)],\tAccuracy: 95.3%,  \t Loss: 0.5278\n",
      "Epoch: 12 [2688/5446 (49%)],\tAccuracy: 95.3%,  \t Loss: 0.5366\n",
      "Epoch: 12 [2816/5446 (52%)],\tAccuracy: 93.8%,  \t Loss: 0.6539\n",
      "Epoch: 12 [2944/5446 (54%)],\tAccuracy: 97.7%,  \t Loss: 0.4883\n",
      "Epoch: 12 [3072/5446 (56%)],\tAccuracy: 96.9%,  \t Loss: 0.4526\n",
      "Epoch: 12 [3200/5446 (59%)],\tAccuracy: 94.5%,  \t Loss: 0.5470\n",
      "Epoch: 12 [3328/5446 (61%)],\tAccuracy: 96.1%,  \t Loss: 0.5619\n",
      "Epoch: 12 [3456/5446 (63%)],\tAccuracy: 95.3%,  \t Loss: 0.4947\n",
      "Epoch: 12 [3584/5446 (66%)],\tAccuracy: 96.9%,  \t Loss: 0.5062\n",
      "Epoch: 12 [3712/5446 (68%)],\tAccuracy: 96.9%,  \t Loss: 0.4351\n",
      "Epoch: 12 [3840/5446 (71%)],\tAccuracy: 96.1%,  \t Loss: 0.4295\n",
      "Epoch: 12 [3968/5446 (73%)],\tAccuracy: 96.9%,  \t Loss: 0.3998\n",
      "Epoch: 12 [4096/5446 (75%)],\tAccuracy: 97.7%,  \t Loss: 0.4981\n",
      "Epoch: 12 [4224/5446 (78%)],\tAccuracy: 96.1%,  \t Loss: 0.4428\n",
      "Epoch: 12 [4352/5446 (80%)],\tAccuracy: 96.9%,  \t Loss: 0.4975\n",
      "Epoch: 12 [4480/5446 (82%)],\tAccuracy: 98.4%,  \t Loss: 0.3466\n",
      "Epoch: 12 [4608/5446 (85%)],\tAccuracy: 96.1%,  \t Loss: 0.4535\n",
      "Epoch: 12 [4736/5446 (87%)],\tAccuracy: 97.7%,  \t Loss: 0.3851\n",
      "Epoch: 12 [4864/5446 (89%)],\tAccuracy: 96.1%,  \t Loss: 0.5321\n",
      "Epoch: 12 [4992/5446 (92%)],\tAccuracy: 96.1%,  \t Loss: 0.4627\n",
      "Epoch: 12 [5120/5446 (94%)],\tAccuracy: 96.9%,  \t Loss: 0.4164\n",
      "Epoch: 12 [5248/5446 (96%)],\tAccuracy: 95.3%,  \t Loss: 0.4960\n",
      "Epoch: 12 [5376/5446 (99%)],\tAccuracy: 97.7%,  \t Loss: 0.3436\n",
      "Epoch: 12 [5446/5446 (100%)],\tAccuracy: 95.7%,  \t Loss: 0.4170\n",
      "loss_val: 1.2958041429519653 616\n",
      "acc_val: 580 616\n",
      "Validation ==================================================\n",
      "Avg loss (val): 0.0021\n",
      "Avg acc (val): 0.9416\n",
      "\n",
      "Epoch: 13 [128/5446 (2%)],\tAccuracy: 96.1%,  \t Loss: 0.3920\n",
      "Epoch: 13 [256/5446 (5%)],\tAccuracy: 96.9%,  \t Loss: 0.3851\n",
      "Epoch: 13 [384/5446 (7%)],\tAccuracy: 97.7%,  \t Loss: 0.3613\n",
      "Epoch: 13 [512/5446 (9%)],\tAccuracy: 93.8%,  \t Loss: 0.5160\n",
      "Epoch: 13 [640/5446 (12%)],\tAccuracy: 93.0%,  \t Loss: 0.5001\n",
      "Epoch: 13 [768/5446 (14%)],\tAccuracy: 92.2%,  \t Loss: 0.6316\n",
      "Epoch: 13 [896/5446 (16%)],\tAccuracy: 97.7%,  \t Loss: 0.3289\n",
      "Epoch: 13 [1024/5446 (19%)],\tAccuracy: 98.4%,  \t Loss: 0.3649\n",
      "Epoch: 13 [1152/5446 (21%)],\tAccuracy: 95.3%,  \t Loss: 0.3709\n",
      "Epoch: 13 [1280/5446 (24%)],\tAccuracy: 96.1%,  \t Loss: 0.5065\n",
      "Epoch: 13 [1408/5446 (26%)],\tAccuracy: 94.5%,  \t Loss: 0.5095\n",
      "Epoch: 13 [1536/5446 (28%)],\tAccuracy: 98.4%,  \t Loss: 0.3318\n",
      "Epoch: 13 [1664/5446 (31%)],\tAccuracy: 97.7%,  \t Loss: 0.3308\n",
      "Epoch: 13 [1792/5446 (33%)],\tAccuracy: 98.4%,  \t Loss: 0.3974\n",
      "Epoch: 13 [1920/5446 (35%)],\tAccuracy: 98.4%,  \t Loss: 0.2709\n",
      "Epoch: 13 [2048/5446 (38%)],\tAccuracy: 97.7%,  \t Loss: 0.3939\n",
      "Epoch: 13 [2176/5446 (40%)],\tAccuracy: 96.1%,  \t Loss: 0.3783\n",
      "Epoch: 13 [2304/5446 (42%)],\tAccuracy: 99.2%,  \t Loss: 0.3414\n",
      "Epoch: 13 [2432/5446 (45%)],\tAccuracy: 97.7%,  \t Loss: 0.4202\n",
      "Epoch: 13 [2560/5446 (47%)],\tAccuracy: 95.3%,  \t Loss: 0.4839\n",
      "Epoch: 13 [2688/5446 (49%)],\tAccuracy: 95.3%,  \t Loss: 0.4441\n",
      "Epoch: 13 [2816/5446 (52%)],\tAccuracy: 97.7%,  \t Loss: 0.3766\n",
      "Epoch: 13 [2944/5446 (54%)],\tAccuracy: 96.9%,  \t Loss: 0.3632\n",
      "Epoch: 13 [3072/5446 (56%)],\tAccuracy: 98.4%,  \t Loss: 0.3027\n",
      "Epoch: 13 [3200/5446 (59%)],\tAccuracy: 98.4%,  \t Loss: 0.2905\n",
      "Epoch: 13 [3328/5446 (61%)],\tAccuracy: 97.7%,  \t Loss: 0.3134\n",
      "Epoch: 13 [3456/5446 (63%)],\tAccuracy: 97.7%,  \t Loss: 0.4279\n",
      "Epoch: 13 [3584/5446 (66%)],\tAccuracy: 95.3%,  \t Loss: 0.4405\n",
      "Epoch: 13 [3712/5446 (68%)],\tAccuracy: 94.5%,  \t Loss: 0.4910\n",
      "Epoch: 13 [3840/5446 (71%)],\tAccuracy: 94.5%,  \t Loss: 0.5069\n",
      "Epoch: 13 [3968/5446 (73%)],\tAccuracy: 93.8%,  \t Loss: 0.5202\n",
      "Epoch: 13 [4096/5446 (75%)],\tAccuracy: 96.9%,  \t Loss: 0.3701\n",
      "Epoch: 13 [4224/5446 (78%)],\tAccuracy: 96.1%,  \t Loss: 0.3349\n",
      "Epoch: 13 [4352/5446 (80%)],\tAccuracy: 95.3%,  \t Loss: 0.5015\n",
      "Epoch: 13 [4480/5446 (82%)],\tAccuracy: 97.7%,  \t Loss: 0.3359\n",
      "Epoch: 13 [4608/5446 (85%)],\tAccuracy: 96.9%,  \t Loss: 0.3704\n",
      "Epoch: 13 [4736/5446 (87%)],\tAccuracy: 96.9%,  \t Loss: 0.3564\n",
      "Epoch: 13 [4864/5446 (89%)],\tAccuracy: 95.3%,  \t Loss: 0.3582\n",
      "Epoch: 13 [4992/5446 (92%)],\tAccuracy: 94.5%,  \t Loss: 0.4893\n",
      "Epoch: 13 [5120/5446 (94%)],\tAccuracy: 96.9%,  \t Loss: 0.3726\n",
      "Epoch: 13 [5248/5446 (96%)],\tAccuracy: 98.4%,  \t Loss: 0.2508\n",
      "Epoch: 13 [5376/5446 (99%)],\tAccuracy: 95.3%,  \t Loss: 0.4013\n",
      "Epoch: 13 [5446/5446 (100%)],\tAccuracy: 95.7%,  \t Loss: 0.3919\n",
      "loss_val: 1.1843804121017456 616\n",
      "acc_val: 582 616\n",
      "Validation ==================================================\n",
      "Avg loss (val): 0.0019\n",
      "Avg acc (val): 0.9448\n",
      "\n",
      "Epoch: 14 [128/5446 (2%)],\tAccuracy: 98.4%,  \t Loss: 0.2424\n",
      "Epoch: 14 [256/5446 (5%)],\tAccuracy: 96.1%,  \t Loss: 0.3875\n",
      "Epoch: 14 [384/5446 (7%)],\tAccuracy: 99.2%,  \t Loss: 0.2617\n",
      "Epoch: 14 [512/5446 (9%)],\tAccuracy: 99.2%,  \t Loss: 0.2334\n",
      "Epoch: 14 [640/5446 (12%)],\tAccuracy: 98.4%,  \t Loss: 0.3305\n",
      "Epoch: 14 [768/5446 (14%)],\tAccuracy: 100.0%,  \t Loss: 0.2285\n",
      "Epoch: 14 [896/5446 (16%)],\tAccuracy: 98.4%,  \t Loss: 0.2804\n",
      "Epoch: 14 [1024/5446 (19%)],\tAccuracy: 94.5%,  \t Loss: 0.3381\n",
      "Epoch: 14 [1152/5446 (21%)],\tAccuracy: 99.2%,  \t Loss: 0.2137\n",
      "Epoch: 14 [1280/5446 (24%)],\tAccuracy: 96.1%,  \t Loss: 0.2936\n",
      "Epoch: 14 [1408/5446 (26%)],\tAccuracy: 99.2%,  \t Loss: 0.2501\n",
      "Epoch: 14 [1536/5446 (28%)],\tAccuracy: 96.1%,  \t Loss: 0.3431\n",
      "Epoch: 14 [1664/5446 (31%)],\tAccuracy: 97.7%,  \t Loss: 0.3080\n",
      "Epoch: 14 [1792/5446 (33%)],\tAccuracy: 100.0%,  \t Loss: 0.2587\n",
      "Epoch: 14 [1920/5446 (35%)],\tAccuracy: 99.2%,  \t Loss: 0.2592\n",
      "Epoch: 14 [2048/5446 (38%)],\tAccuracy: 97.7%,  \t Loss: 0.2870\n",
      "Epoch: 14 [2176/5446 (40%)],\tAccuracy: 98.4%,  \t Loss: 0.2524\n",
      "Epoch: 14 [2304/5446 (42%)],\tAccuracy: 98.4%,  \t Loss: 0.2908\n",
      "Epoch: 14 [2432/5446 (45%)],\tAccuracy: 97.7%,  \t Loss: 0.2628\n",
      "Epoch: 14 [2560/5446 (47%)],\tAccuracy: 96.9%,  \t Loss: 0.3984\n",
      "Epoch: 14 [2688/5446 (49%)],\tAccuracy: 96.9%,  \t Loss: 0.3745\n",
      "Epoch: 14 [2816/5446 (52%)],\tAccuracy: 96.9%,  \t Loss: 0.3366\n",
      "Epoch: 14 [2944/5446 (54%)],\tAccuracy: 98.4%,  \t Loss: 0.2008\n",
      "Epoch: 14 [3072/5446 (56%)],\tAccuracy: 96.9%,  \t Loss: 0.3563\n",
      "Epoch: 14 [3200/5446 (59%)],\tAccuracy: 96.9%,  \t Loss: 0.2561\n",
      "Epoch: 14 [3328/5446 (61%)],\tAccuracy: 93.8%,  \t Loss: 0.4911\n",
      "Epoch: 14 [3456/5446 (63%)],\tAccuracy: 97.7%,  \t Loss: 0.3815\n",
      "Epoch: 14 [3584/5446 (66%)],\tAccuracy: 96.9%,  \t Loss: 0.2650\n",
      "Epoch: 14 [3712/5446 (68%)],\tAccuracy: 99.2%,  \t Loss: 0.3481\n",
      "Epoch: 14 [3840/5446 (71%)],\tAccuracy: 97.7%,  \t Loss: 0.2348\n",
      "Epoch: 14 [3968/5446 (73%)],\tAccuracy: 96.1%,  \t Loss: 0.2602\n",
      "Epoch: 14 [4096/5446 (75%)],\tAccuracy: 98.4%,  \t Loss: 0.3291\n",
      "Epoch: 14 [4224/5446 (78%)],\tAccuracy: 98.4%,  \t Loss: 0.3028\n",
      "Epoch: 14 [4352/5446 (80%)],\tAccuracy: 96.1%,  \t Loss: 0.3892\n",
      "Epoch: 14 [4480/5446 (82%)],\tAccuracy: 98.4%,  \t Loss: 0.2370\n",
      "Epoch: 14 [4608/5446 (85%)],\tAccuracy: 99.2%,  \t Loss: 0.2784\n",
      "Epoch: 14 [4736/5446 (87%)],\tAccuracy: 97.7%,  \t Loss: 0.2361\n",
      "Epoch: 14 [4864/5446 (89%)],\tAccuracy: 95.3%,  \t Loss: 0.3487\n",
      "Epoch: 14 [4992/5446 (92%)],\tAccuracy: 93.8%,  \t Loss: 0.4725\n",
      "Epoch: 14 [5120/5446 (94%)],\tAccuracy: 94.5%,  \t Loss: 0.4779\n",
      "Epoch: 14 [5248/5446 (96%)],\tAccuracy: 99.2%,  \t Loss: 0.2350\n",
      "Epoch: 14 [5376/5446 (99%)],\tAccuracy: 97.7%,  \t Loss: 0.2755\n",
      "Epoch: 14 [5446/5446 (100%)],\tAccuracy: 98.6%,  \t Loss: 0.1817\n",
      "loss_val: 1.0576432049274445 616\n",
      "acc_val: 581 616\n",
      "Validation ==================================================\n",
      "Avg loss (val): 0.0017\n",
      "Avg acc (val): 0.9432\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 [128/5446 (2%)],\tAccuracy: 98.4%,  \t Loss: 0.2695\n",
      "Epoch: 15 [256/5446 (5%)],\tAccuracy: 97.7%,  \t Loss: 0.3358\n",
      "Epoch: 15 [384/5446 (7%)],\tAccuracy: 95.3%,  \t Loss: 0.3523\n",
      "Epoch: 15 [512/5446 (9%)],\tAccuracy: 99.2%,  \t Loss: 0.1633\n",
      "Epoch: 15 [640/5446 (12%)],\tAccuracy: 96.9%,  \t Loss: 0.3370\n",
      "Epoch: 15 [768/5446 (14%)],\tAccuracy: 99.2%,  \t Loss: 0.2152\n",
      "Epoch: 15 [896/5446 (16%)],\tAccuracy: 96.9%,  \t Loss: 0.3031\n",
      "Epoch: 15 [1024/5446 (19%)],\tAccuracy: 97.7%,  \t Loss: 0.2636\n",
      "Epoch: 15 [1152/5446 (21%)],\tAccuracy: 99.2%,  \t Loss: 0.1691\n",
      "Epoch: 15 [1280/5446 (24%)],\tAccuracy: 98.4%,  \t Loss: 0.2754\n",
      "Epoch: 15 [1408/5446 (26%)],\tAccuracy: 99.2%,  \t Loss: 0.2121\n",
      "Epoch: 15 [1536/5446 (28%)],\tAccuracy: 97.7%,  \t Loss: 0.2226\n",
      "Epoch: 15 [1664/5446 (31%)],\tAccuracy: 96.9%,  \t Loss: 0.2868\n",
      "Epoch: 15 [1792/5446 (33%)],\tAccuracy: 98.4%,  \t Loss: 0.1908\n",
      "Epoch: 15 [1920/5446 (35%)],\tAccuracy: 96.9%,  \t Loss: 0.3570\n",
      "Epoch: 15 [2048/5446 (38%)],\tAccuracy: 96.9%,  \t Loss: 0.4037\n",
      "Epoch: 15 [2176/5446 (40%)],\tAccuracy: 97.7%,  \t Loss: 0.2076\n",
      "Epoch: 15 [2304/5446 (42%)],\tAccuracy: 97.7%,  \t Loss: 0.2748\n",
      "Epoch: 15 [2432/5446 (45%)],\tAccuracy: 98.4%,  \t Loss: 0.2186\n",
      "Epoch: 15 [2560/5446 (47%)],\tAccuracy: 97.7%,  \t Loss: 0.3119\n",
      "Epoch: 15 [2688/5446 (49%)],\tAccuracy: 94.5%,  \t Loss: 0.3587\n",
      "Epoch: 15 [2816/5446 (52%)],\tAccuracy: 97.7%,  \t Loss: 0.2495\n",
      "Epoch: 15 [2944/5446 (54%)],\tAccuracy: 96.9%,  \t Loss: 0.2658\n",
      "Epoch: 15 [3072/5446 (56%)],\tAccuracy: 96.1%,  \t Loss: 0.3692\n",
      "Epoch: 15 [3200/5446 (59%)],\tAccuracy: 98.4%,  \t Loss: 0.2205\n",
      "Epoch: 15 [3328/5446 (61%)],\tAccuracy: 95.3%,  \t Loss: 0.2847\n",
      "Epoch: 15 [3456/5446 (63%)],\tAccuracy: 97.7%,  \t Loss: 0.2487\n",
      "Epoch: 15 [3584/5446 (66%)],\tAccuracy: 98.4%,  \t Loss: 0.1995\n",
      "Epoch: 15 [3712/5446 (68%)],\tAccuracy: 98.4%,  \t Loss: 0.1813\n",
      "Epoch: 15 [3840/5446 (71%)],\tAccuracy: 97.7%,  \t Loss: 0.2634\n",
      "Epoch: 15 [3968/5446 (73%)],\tAccuracy: 99.2%,  \t Loss: 0.2173\n",
      "Epoch: 15 [4096/5446 (75%)],\tAccuracy: 99.2%,  \t Loss: 0.2694\n",
      "Epoch: 15 [4224/5446 (78%)],\tAccuracy: 93.8%,  \t Loss: 0.3781\n",
      "Epoch: 15 [4352/5446 (80%)],\tAccuracy: 98.4%,  \t Loss: 0.2321\n",
      "Epoch: 15 [4480/5446 (82%)],\tAccuracy: 97.7%,  \t Loss: 0.2983\n",
      "Epoch: 15 [4608/5446 (85%)],\tAccuracy: 96.9%,  \t Loss: 0.3540\n",
      "Epoch: 15 [4736/5446 (87%)],\tAccuracy: 96.9%,  \t Loss: 0.2666\n",
      "Epoch: 15 [4864/5446 (89%)],\tAccuracy: 96.9%,  \t Loss: 0.3147\n",
      "Epoch: 15 [4992/5446 (92%)],\tAccuracy: 98.4%,  \t Loss: 0.2412\n",
      "Epoch: 15 [5120/5446 (94%)],\tAccuracy: 99.2%,  \t Loss: 0.1585\n",
      "Epoch: 15 [5248/5446 (96%)],\tAccuracy: 100.0%,  \t Loss: 0.1107\n",
      "Epoch: 15 [5376/5446 (99%)],\tAccuracy: 98.4%,  \t Loss: 0.2957\n",
      "Epoch: 15 [5446/5446 (100%)],\tAccuracy: 95.7%,  \t Loss: 0.3035\n",
      "loss_val: 0.9587371796369553 616\n",
      "acc_val: 586 616\n",
      "Validation ==================================================\n",
      "Avg loss (val): 0.0016\n",
      "Avg acc (val): 0.9513\n",
      "\n",
      "Epoch: 16 [128/5446 (2%)],\tAccuracy: 100.0%,  \t Loss: 0.1286\n",
      "Epoch: 16 [256/5446 (5%)],\tAccuracy: 96.9%,  \t Loss: 0.2546\n",
      "Epoch: 16 [384/5446 (7%)],\tAccuracy: 97.7%,  \t Loss: 0.2599\n",
      "Epoch: 16 [512/5446 (9%)],\tAccuracy: 98.4%,  \t Loss: 0.1944\n",
      "Epoch: 16 [640/5446 (12%)],\tAccuracy: 97.7%,  \t Loss: 0.2300\n",
      "Epoch: 16 [768/5446 (14%)],\tAccuracy: 99.2%,  \t Loss: 0.2089\n",
      "Epoch: 16 [896/5446 (16%)],\tAccuracy: 100.0%,  \t Loss: 0.1555\n",
      "Epoch: 16 [1024/5446 (19%)],\tAccuracy: 98.4%,  \t Loss: 0.2394\n",
      "Epoch: 16 [1152/5446 (21%)],\tAccuracy: 98.4%,  \t Loss: 0.1887\n",
      "Epoch: 16 [1280/5446 (24%)],\tAccuracy: 96.9%,  \t Loss: 0.2931\n",
      "Epoch: 16 [1408/5446 (26%)],\tAccuracy: 99.2%,  \t Loss: 0.2332\n",
      "Epoch: 16 [1536/5446 (28%)],\tAccuracy: 99.2%,  \t Loss: 0.1610\n",
      "Epoch: 16 [1664/5446 (31%)],\tAccuracy: 99.2%,  \t Loss: 0.1653\n",
      "Epoch: 16 [1792/5446 (33%)],\tAccuracy: 98.4%,  \t Loss: 0.2240\n",
      "Epoch: 16 [1920/5446 (35%)],\tAccuracy: 99.2%,  \t Loss: 0.2183\n",
      "Epoch: 16 [2048/5446 (38%)],\tAccuracy: 98.4%,  \t Loss: 0.1715\n",
      "Epoch: 16 [2176/5446 (40%)],\tAccuracy: 96.9%,  \t Loss: 0.2965\n",
      "Epoch: 16 [2304/5446 (42%)],\tAccuracy: 99.2%,  \t Loss: 0.1681\n",
      "Epoch: 16 [2432/5446 (45%)],\tAccuracy: 98.4%,  \t Loss: 0.2470\n",
      "Epoch: 16 [2560/5446 (47%)],\tAccuracy: 98.4%,  \t Loss: 0.2327\n",
      "Epoch: 16 [2688/5446 (49%)],\tAccuracy: 96.1%,  \t Loss: 0.3497\n",
      "Epoch: 16 [2816/5446 (52%)],\tAccuracy: 100.0%,  \t Loss: 0.1450\n",
      "Epoch: 16 [2944/5446 (54%)],\tAccuracy: 99.2%,  \t Loss: 0.1835\n",
      "Epoch: 16 [3072/5446 (56%)],\tAccuracy: 99.2%,  \t Loss: 0.1797\n",
      "Epoch: 16 [3200/5446 (59%)],\tAccuracy: 100.0%,  \t Loss: 0.1392\n",
      "Epoch: 16 [3328/5446 (61%)],\tAccuracy: 99.2%,  \t Loss: 0.1549\n",
      "Epoch: 16 [3456/5446 (63%)],\tAccuracy: 95.3%,  \t Loss: 0.3905\n",
      "Epoch: 16 [3584/5446 (66%)],\tAccuracy: 98.4%,  \t Loss: 0.1779\n",
      "Epoch: 16 [3712/5446 (68%)],\tAccuracy: 100.0%,  \t Loss: 0.1875\n",
      "Epoch: 16 [3840/5446 (71%)],\tAccuracy: 99.2%,  \t Loss: 0.1352\n",
      "Epoch: 16 [3968/5446 (73%)],\tAccuracy: 99.2%,  \t Loss: 0.1301\n",
      "Epoch: 16 [4096/5446 (75%)],\tAccuracy: 98.4%,  \t Loss: 0.2263\n",
      "Epoch: 16 [4224/5446 (78%)],\tAccuracy: 99.2%,  \t Loss: 0.2041\n",
      "Epoch: 16 [4352/5446 (80%)],\tAccuracy: 100.0%,  \t Loss: 0.1371\n",
      "Epoch: 16 [4480/5446 (82%)],\tAccuracy: 99.2%,  \t Loss: 0.2093\n",
      "Epoch: 16 [4608/5446 (85%)],\tAccuracy: 98.4%,  \t Loss: 0.1834\n",
      "Epoch: 16 [4736/5446 (87%)],\tAccuracy: 96.1%,  \t Loss: 0.2705\n",
      "Epoch: 16 [4864/5446 (89%)],\tAccuracy: 97.7%,  \t Loss: 0.2418\n",
      "Epoch: 16 [4992/5446 (92%)],\tAccuracy: 97.7%,  \t Loss: 0.2641\n",
      "Epoch: 16 [5120/5446 (94%)],\tAccuracy: 98.4%,  \t Loss: 0.1104\n",
      "Epoch: 16 [5248/5446 (96%)],\tAccuracy: 99.2%,  \t Loss: 0.1704\n",
      "Epoch: 16 [5376/5446 (99%)],\tAccuracy: 98.4%,  \t Loss: 0.2467\n",
      "Epoch: 16 [5446/5446 (100%)],\tAccuracy: 100.0%,  \t Loss: 0.1416\n",
      "loss_val: 0.890904575586319 616\n",
      "acc_val: 588 616\n",
      "Validation ==================================================\n",
      "Avg loss (val): 0.0014\n",
      "Avg acc (val): 0.9545\n",
      "\n",
      "Epoch: 17 [128/5446 (2%)],\tAccuracy: 99.2%,  \t Loss: 0.1399\n",
      "Epoch: 17 [256/5446 (5%)],\tAccuracy: 99.2%,  \t Loss: 0.1739\n",
      "Epoch: 17 [384/5446 (7%)],\tAccuracy: 99.2%,  \t Loss: 0.1371\n",
      "Epoch: 17 [512/5446 (9%)],\tAccuracy: 99.2%,  \t Loss: 0.1665\n",
      "Epoch: 17 [640/5446 (12%)],\tAccuracy: 100.0%,  \t Loss: 0.1449\n",
      "Epoch: 17 [768/5446 (14%)],\tAccuracy: 99.2%,  \t Loss: 0.1853\n",
      "Epoch: 17 [896/5446 (16%)],\tAccuracy: 99.2%,  \t Loss: 0.1458\n",
      "Epoch: 17 [1024/5446 (19%)],\tAccuracy: 100.0%,  \t Loss: 0.0999\n",
      "Epoch: 17 [1152/5446 (21%)],\tAccuracy: 99.2%,  \t Loss: 0.1279\n",
      "Epoch: 17 [1280/5446 (24%)],\tAccuracy: 100.0%,  \t Loss: 0.1473\n",
      "Epoch: 17 [1408/5446 (26%)],\tAccuracy: 99.2%,  \t Loss: 0.1732\n",
      "Epoch: 17 [1536/5446 (28%)],\tAccuracy: 100.0%,  \t Loss: 0.0996\n",
      "Epoch: 17 [1664/5446 (31%)],\tAccuracy: 98.4%,  \t Loss: 0.1435\n",
      "Epoch: 17 [1792/5446 (33%)],\tAccuracy: 99.2%,  \t Loss: 0.1260\n",
      "Epoch: 17 [1920/5446 (35%)],\tAccuracy: 100.0%,  \t Loss: 0.1244\n",
      "Epoch: 17 [2048/5446 (38%)],\tAccuracy: 98.4%,  \t Loss: 0.1392\n",
      "Epoch: 17 [2176/5446 (40%)],\tAccuracy: 98.4%,  \t Loss: 0.1688\n",
      "Epoch: 17 [2304/5446 (42%)],\tAccuracy: 98.4%,  \t Loss: 0.2104\n",
      "Epoch: 17 [2432/5446 (45%)],\tAccuracy: 100.0%,  \t Loss: 0.0996\n",
      "Epoch: 17 [2560/5446 (47%)],\tAccuracy: 100.0%,  \t Loss: 0.1314\n",
      "Epoch: 17 [2688/5446 (49%)],\tAccuracy: 98.4%,  \t Loss: 0.2037\n",
      "Epoch: 17 [2816/5446 (52%)],\tAccuracy: 100.0%,  \t Loss: 0.1401\n",
      "Epoch: 17 [2944/5446 (54%)],\tAccuracy: 98.4%,  \t Loss: 0.2526\n",
      "Epoch: 17 [3072/5446 (56%)],\tAccuracy: 100.0%,  \t Loss: 0.0730\n",
      "Epoch: 17 [3200/5446 (59%)],\tAccuracy: 100.0%,  \t Loss: 0.1285\n",
      "Epoch: 17 [3328/5446 (61%)],\tAccuracy: 99.2%,  \t Loss: 0.1427\n",
      "Epoch: 17 [3456/5446 (63%)],\tAccuracy: 100.0%,  \t Loss: 0.1780\n",
      "Epoch: 17 [3584/5446 (66%)],\tAccuracy: 100.0%,  \t Loss: 0.1400\n",
      "Epoch: 17 [3712/5446 (68%)],\tAccuracy: 97.7%,  \t Loss: 0.2647\n",
      "Epoch: 17 [3840/5446 (71%)],\tAccuracy: 100.0%,  \t Loss: 0.0859\n",
      "Epoch: 17 [3968/5446 (73%)],\tAccuracy: 100.0%,  \t Loss: 0.1525\n",
      "Epoch: 17 [4096/5446 (75%)],\tAccuracy: 96.1%,  \t Loss: 0.2524\n",
      "Epoch: 17 [4224/5446 (78%)],\tAccuracy: 100.0%,  \t Loss: 0.0948\n",
      "Epoch: 17 [4352/5446 (80%)],\tAccuracy: 98.4%,  \t Loss: 0.1642\n",
      "Epoch: 17 [4480/5446 (82%)],\tAccuracy: 100.0%,  \t Loss: 0.0988\n",
      "Epoch: 17 [4608/5446 (85%)],\tAccuracy: 98.4%,  \t Loss: 0.1847\n",
      "Epoch: 17 [4736/5446 (87%)],\tAccuracy: 99.2%,  \t Loss: 0.1109\n",
      "Epoch: 17 [4864/5446 (89%)],\tAccuracy: 96.1%,  \t Loss: 0.1983\n",
      "Epoch: 17 [4992/5446 (92%)],\tAccuracy: 98.4%,  \t Loss: 0.1834\n",
      "Epoch: 17 [5120/5446 (94%)],\tAccuracy: 98.4%,  \t Loss: 0.1493\n",
      "Epoch: 17 [5248/5446 (96%)],\tAccuracy: 97.7%,  \t Loss: 0.1759\n",
      "Epoch: 17 [5376/5446 (99%)],\tAccuracy: 98.4%,  \t Loss: 0.1706\n",
      "Epoch: 17 [5446/5446 (100%)],\tAccuracy: 98.6%,  \t Loss: 0.2167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_val: 0.8594867289066315 616\n",
      "acc_val: 584 616\n",
      "Validation ==================================================\n",
      "Avg loss (val): 0.0014\n",
      "Avg acc (val): 0.9481\n",
      "\n",
      "Epoch: 18 [128/5446 (2%)],\tAccuracy: 98.4%,  \t Loss: 0.2391\n",
      "Epoch: 18 [256/5446 (5%)],\tAccuracy: 99.2%,  \t Loss: 0.1011\n",
      "Epoch: 18 [384/5446 (7%)],\tAccuracy: 99.2%,  \t Loss: 0.1420\n",
      "Epoch: 18 [512/5446 (9%)],\tAccuracy: 100.0%,  \t Loss: 0.0813\n",
      "Epoch: 18 [640/5446 (12%)],\tAccuracy: 98.4%,  \t Loss: 0.1276\n",
      "Epoch: 18 [768/5446 (14%)],\tAccuracy: 100.0%,  \t Loss: 0.1075\n",
      "Epoch: 18 [896/5446 (16%)],\tAccuracy: 97.7%,  \t Loss: 0.1867\n",
      "Epoch: 18 [1024/5446 (19%)],\tAccuracy: 98.4%,  \t Loss: 0.1402\n",
      "Epoch: 18 [1152/5446 (21%)],\tAccuracy: 98.4%,  \t Loss: 0.1284\n",
      "Epoch: 18 [1280/5446 (24%)],\tAccuracy: 99.2%,  \t Loss: 0.1135\n",
      "Epoch: 18 [1408/5446 (26%)],\tAccuracy: 99.2%,  \t Loss: 0.0892\n",
      "Epoch: 18 [1536/5446 (28%)],\tAccuracy: 99.2%,  \t Loss: 0.1093\n",
      "Epoch: 18 [1664/5446 (31%)],\tAccuracy: 99.2%,  \t Loss: 0.1188\n",
      "Epoch: 18 [1792/5446 (33%)],\tAccuracy: 99.2%,  \t Loss: 0.0949\n",
      "Epoch: 18 [1920/5446 (35%)],\tAccuracy: 98.4%,  \t Loss: 0.1498\n",
      "Epoch: 18 [2048/5446 (38%)],\tAccuracy: 100.0%,  \t Loss: 0.0745\n",
      "Epoch: 18 [2176/5446 (40%)],\tAccuracy: 98.4%,  \t Loss: 0.1542\n",
      "Epoch: 18 [2304/5446 (42%)],\tAccuracy: 99.2%,  \t Loss: 0.1243\n",
      "Epoch: 18 [2432/5446 (45%)],\tAccuracy: 99.2%,  \t Loss: 0.0991\n",
      "Epoch: 18 [2560/5446 (47%)],\tAccuracy: 99.2%,  \t Loss: 0.1193\n",
      "Epoch: 18 [2688/5446 (49%)],\tAccuracy: 100.0%,  \t Loss: 0.0825\n",
      "Epoch: 18 [2816/5446 (52%)],\tAccuracy: 100.0%,  \t Loss: 0.0948\n",
      "Epoch: 18 [2944/5446 (54%)],\tAccuracy: 99.2%,  \t Loss: 0.1313\n",
      "Epoch: 18 [3072/5446 (56%)],\tAccuracy: 99.2%,  \t Loss: 0.1372\n",
      "Epoch: 18 [3200/5446 (59%)],\tAccuracy: 99.2%,  \t Loss: 0.1317\n",
      "Epoch: 18 [3328/5446 (61%)],\tAccuracy: 98.4%,  \t Loss: 0.2063\n",
      "Epoch: 18 [3456/5446 (63%)],\tAccuracy: 98.4%,  \t Loss: 0.1280\n",
      "Epoch: 18 [3584/5446 (66%)],\tAccuracy: 100.0%,  \t Loss: 0.1181\n",
      "Epoch: 18 [3712/5446 (68%)],\tAccuracy: 100.0%,  \t Loss: 0.1560\n",
      "Epoch: 18 [3840/5446 (71%)],\tAccuracy: 99.2%,  \t Loss: 0.2094\n",
      "Epoch: 18 [3968/5446 (73%)],\tAccuracy: 97.7%,  \t Loss: 0.2413\n",
      "Epoch: 18 [4096/5446 (75%)],\tAccuracy: 97.7%,  \t Loss: 0.1878\n",
      "Epoch: 18 [4224/5446 (78%)],\tAccuracy: 100.0%,  \t Loss: 0.1649\n",
      "Epoch: 18 [4352/5446 (80%)],\tAccuracy: 99.2%,  \t Loss: 0.1360\n",
      "Epoch: 18 [4480/5446 (82%)],\tAccuracy: 99.2%,  \t Loss: 0.0797\n",
      "Epoch: 18 [4608/5446 (85%)],\tAccuracy: 100.0%,  \t Loss: 0.1094\n",
      "Epoch: 18 [4736/5446 (87%)],\tAccuracy: 99.2%,  \t Loss: 0.1018\n",
      "Epoch: 18 [4864/5446 (89%)],\tAccuracy: 98.4%,  \t Loss: 0.2022\n",
      "Epoch: 18 [4992/5446 (92%)],\tAccuracy: 99.2%,  \t Loss: 0.1699\n",
      "Epoch: 18 [5120/5446 (94%)],\tAccuracy: 100.0%,  \t Loss: 0.0686\n",
      "Epoch: 18 [5248/5446 (96%)],\tAccuracy: 98.4%,  \t Loss: 0.1973\n",
      "Epoch: 18 [5376/5446 (99%)],\tAccuracy: 98.4%,  \t Loss: 0.1654\n",
      "Epoch: 18 [5446/5446 (100%)],\tAccuracy: 100.0%,  \t Loss: 0.1192\n",
      "loss_val: 0.8592941015958786 616\n",
      "acc_val: 588 616\n",
      "Validation ==================================================\n",
      "Avg loss (val): 0.0014\n",
      "Avg acc (val): 0.9545\n",
      "\n",
      "Epoch: 19 [128/5446 (2%)],\tAccuracy: 99.2%,  \t Loss: 0.1010\n",
      "Epoch: 19 [256/5446 (5%)],\tAccuracy: 100.0%,  \t Loss: 0.0836\n",
      "Epoch: 19 [384/5446 (7%)],\tAccuracy: 99.2%,  \t Loss: 0.0952\n",
      "Epoch: 19 [512/5446 (9%)],\tAccuracy: 99.2%,  \t Loss: 0.1749\n",
      "Epoch: 19 [640/5446 (12%)],\tAccuracy: 100.0%,  \t Loss: 0.0791\n",
      "Epoch: 19 [768/5446 (14%)],\tAccuracy: 98.4%,  \t Loss: 0.1816\n",
      "Epoch: 19 [896/5446 (16%)],\tAccuracy: 99.2%,  \t Loss: 0.1527\n",
      "Epoch: 19 [1024/5446 (19%)],\tAccuracy: 94.5%,  \t Loss: 0.3431\n",
      "Epoch: 19 [1152/5446 (21%)],\tAccuracy: 99.2%,  \t Loss: 0.1297\n",
      "Epoch: 19 [1280/5446 (24%)],\tAccuracy: 99.2%,  \t Loss: 0.1224\n",
      "Epoch: 19 [1408/5446 (26%)],\tAccuracy: 100.0%,  \t Loss: 0.0755\n",
      "Epoch: 19 [1536/5446 (28%)],\tAccuracy: 97.7%,  \t Loss: 0.1581\n",
      "Epoch: 19 [1664/5446 (31%)],\tAccuracy: 99.2%,  \t Loss: 0.1010\n",
      "Epoch: 19 [1792/5446 (33%)],\tAccuracy: 99.2%,  \t Loss: 0.0620\n",
      "Epoch: 19 [1920/5446 (35%)],\tAccuracy: 100.0%,  \t Loss: 0.1035\n",
      "Epoch: 19 [2048/5446 (38%)],\tAccuracy: 99.2%,  \t Loss: 0.0960\n",
      "Epoch: 19 [2176/5446 (40%)],\tAccuracy: 100.0%,  \t Loss: 0.0877\n",
      "Epoch: 19 [2304/5446 (42%)],\tAccuracy: 99.2%,  \t Loss: 0.0894\n",
      "Epoch: 19 [2432/5446 (45%)],\tAccuracy: 100.0%,  \t Loss: 0.0886\n",
      "Epoch: 19 [2560/5446 (47%)],\tAccuracy: 99.2%,  \t Loss: 0.1502\n",
      "Epoch: 19 [2688/5446 (49%)],\tAccuracy: 99.2%,  \t Loss: 0.1049\n",
      "Epoch: 19 [2816/5446 (52%)],\tAccuracy: 99.2%,  \t Loss: 0.1200\n",
      "Epoch: 19 [2944/5446 (54%)],\tAccuracy: 99.2%,  \t Loss: 0.1110\n",
      "Epoch: 19 [3072/5446 (56%)],\tAccuracy: 98.4%,  \t Loss: 0.1598\n",
      "Epoch: 19 [3200/5446 (59%)],\tAccuracy: 97.7%,  \t Loss: 0.2084\n",
      "Epoch: 19 [3328/5446 (61%)],\tAccuracy: 99.2%,  \t Loss: 0.1465\n",
      "Epoch: 19 [3456/5446 (63%)],\tAccuracy: 99.2%,  \t Loss: 0.1615\n",
      "Epoch: 19 [3584/5446 (66%)],\tAccuracy: 99.2%,  \t Loss: 0.1300\n",
      "Epoch: 19 [3712/5446 (68%)],\tAccuracy: 98.4%,  \t Loss: 0.1619\n",
      "Epoch: 19 [3840/5446 (71%)],\tAccuracy: 99.2%,  \t Loss: 0.1396\n",
      "Epoch: 19 [3968/5446 (73%)],\tAccuracy: 97.7%,  \t Loss: 0.2118\n",
      "Epoch: 19 [4096/5446 (75%)],\tAccuracy: 98.4%,  \t Loss: 0.0958\n",
      "Epoch: 19 [4224/5446 (78%)],\tAccuracy: 100.0%,  \t Loss: 0.0986\n",
      "Epoch: 19 [4352/5446 (80%)],\tAccuracy: 98.4%,  \t Loss: 0.0898\n",
      "Epoch: 19 [4480/5446 (82%)],\tAccuracy: 99.2%,  \t Loss: 0.1361\n",
      "Epoch: 19 [4608/5446 (85%)],\tAccuracy: 100.0%,  \t Loss: 0.1279\n",
      "Epoch: 19 [4736/5446 (87%)],\tAccuracy: 99.2%,  \t Loss: 0.1095\n",
      "Epoch: 19 [4864/5446 (89%)],\tAccuracy: 100.0%,  \t Loss: 0.0802\n",
      "Epoch: 19 [4992/5446 (92%)],\tAccuracy: 99.2%,  \t Loss: 0.1282\n",
      "Epoch: 19 [5120/5446 (94%)],\tAccuracy: 100.0%,  \t Loss: 0.0851\n",
      "Epoch: 19 [5248/5446 (96%)],\tAccuracy: 99.2%,  \t Loss: 0.0738\n",
      "Epoch: 19 [5376/5446 (99%)],\tAccuracy: 99.2%,  \t Loss: 0.1670\n",
      "Epoch: 19 [5446/5446 (100%)],\tAccuracy: 98.6%,  \t Loss: 0.1332\n",
      "loss_val: 0.7908566296100616 616\n",
      "acc_val: 589 616\n",
      "Validation ==================================================\n",
      "Avg loss (val): 0.0013\n",
      "Avg acc (val): 0.9562\n",
      "\n",
      "Epoch: 20 [128/5446 (2%)],\tAccuracy: 99.2%,  \t Loss: 0.1391\n",
      "Epoch: 20 [256/5446 (5%)],\tAccuracy: 99.2%,  \t Loss: 0.0821\n",
      "Epoch: 20 [384/5446 (7%)],\tAccuracy: 100.0%,  \t Loss: 0.0868\n",
      "Epoch: 20 [512/5446 (9%)],\tAccuracy: 99.2%,  \t Loss: 0.1233\n",
      "Epoch: 20 [640/5446 (12%)],\tAccuracy: 100.0%,  \t Loss: 0.0874\n",
      "Epoch: 20 [768/5446 (14%)],\tAccuracy: 99.2%,  \t Loss: 0.0961\n",
      "Epoch: 20 [896/5446 (16%)],\tAccuracy: 99.2%,  \t Loss: 0.1112\n",
      "Epoch: 20 [1024/5446 (19%)],\tAccuracy: 100.0%,  \t Loss: 0.0500\n",
      "Epoch: 20 [1152/5446 (21%)],\tAccuracy: 99.2%,  \t Loss: 0.1176\n",
      "Epoch: 20 [1280/5446 (24%)],\tAccuracy: 99.2%,  \t Loss: 0.1080\n",
      "Epoch: 20 [1408/5446 (26%)],\tAccuracy: 100.0%,  \t Loss: 0.0812\n",
      "Epoch: 20 [1536/5446 (28%)],\tAccuracy: 100.0%,  \t Loss: 0.0752\n",
      "Epoch: 20 [1664/5446 (31%)],\tAccuracy: 100.0%,  \t Loss: 0.0585\n",
      "Epoch: 20 [1792/5446 (33%)],\tAccuracy: 98.4%,  \t Loss: 0.0802\n",
      "Epoch: 20 [1920/5446 (35%)],\tAccuracy: 100.0%,  \t Loss: 0.0701\n",
      "Epoch: 20 [2048/5446 (38%)],\tAccuracy: 99.2%,  \t Loss: 0.1050\n",
      "Epoch: 20 [2176/5446 (40%)],\tAccuracy: 100.0%,  \t Loss: 0.0926\n",
      "Epoch: 20 [2304/5446 (42%)],\tAccuracy: 100.0%,  \t Loss: 0.0934\n",
      "Epoch: 20 [2432/5446 (45%)],\tAccuracy: 100.0%,  \t Loss: 0.0388\n",
      "Epoch: 20 [2560/5446 (47%)],\tAccuracy: 100.0%,  \t Loss: 0.0750\n",
      "Epoch: 20 [2688/5446 (49%)],\tAccuracy: 99.2%,  \t Loss: 0.0657\n",
      "Epoch: 20 [2816/5446 (52%)],\tAccuracy: 98.4%,  \t Loss: 0.1436\n",
      "Epoch: 20 [2944/5446 (54%)],\tAccuracy: 99.2%,  \t Loss: 0.0983\n",
      "Epoch: 20 [3072/5446 (56%)],\tAccuracy: 100.0%,  \t Loss: 0.0909\n",
      "Epoch: 20 [3200/5446 (59%)],\tAccuracy: 100.0%,  \t Loss: 0.0874\n",
      "Epoch: 20 [3328/5446 (61%)],\tAccuracy: 100.0%,  \t Loss: 0.0590\n",
      "Epoch: 20 [3456/5446 (63%)],\tAccuracy: 100.0%,  \t Loss: 0.0743\n",
      "Epoch: 20 [3584/5446 (66%)],\tAccuracy: 99.2%,  \t Loss: 0.0988\n",
      "Epoch: 20 [3712/5446 (68%)],\tAccuracy: 100.0%,  \t Loss: 0.0713\n",
      "Epoch: 20 [3840/5446 (71%)],\tAccuracy: 100.0%,  \t Loss: 0.0722\n",
      "Epoch: 20 [3968/5446 (73%)],\tAccuracy: 100.0%,  \t Loss: 0.0523\n",
      "Epoch: 20 [4096/5446 (75%)],\tAccuracy: 98.4%,  \t Loss: 0.1496\n",
      "Epoch: 20 [4224/5446 (78%)],\tAccuracy: 100.0%,  \t Loss: 0.1012\n",
      "Epoch: 20 [4352/5446 (80%)],\tAccuracy: 100.0%,  \t Loss: 0.0582\n",
      "Epoch: 20 [4480/5446 (82%)],\tAccuracy: 100.0%,  \t Loss: 0.0843\n",
      "Epoch: 20 [4608/5446 (85%)],\tAccuracy: 100.0%,  \t Loss: 0.1174\n",
      "Epoch: 20 [4736/5446 (87%)],\tAccuracy: 99.2%,  \t Loss: 0.1045\n",
      "Epoch: 20 [4864/5446 (89%)],\tAccuracy: 100.0%,  \t Loss: 0.0434\n",
      "Epoch: 20 [4992/5446 (92%)],\tAccuracy: 99.2%,  \t Loss: 0.1061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20 [5120/5446 (94%)],\tAccuracy: 99.2%,  \t Loss: 0.1123\n",
      "Epoch: 20 [5248/5446 (96%)],\tAccuracy: 100.0%,  \t Loss: 0.0475\n",
      "Epoch: 20 [5376/5446 (99%)],\tAccuracy: 98.4%,  \t Loss: 0.1745\n",
      "Epoch: 20 [5446/5446 (100%)],\tAccuracy: 100.0%,  \t Loss: 0.0381\n",
      "loss_val: 0.7625980824232101 616\n",
      "acc_val: 589 616\n",
      "Validation ==================================================\n",
      "Avg loss (val): 0.0012\n",
      "Avg acc (val): 0.9562\n",
      "\n",
      "Epoch: 21 [128/5446 (2%)],\tAccuracy: 99.2%,  \t Loss: 0.0891\n",
      "Epoch: 21 [256/5446 (5%)],\tAccuracy: 100.0%,  \t Loss: 0.0460\n",
      "Epoch: 21 [384/5446 (7%)],\tAccuracy: 99.2%,  \t Loss: 0.1308\n",
      "Epoch: 21 [512/5446 (9%)],\tAccuracy: 100.0%,  \t Loss: 0.0458\n",
      "Epoch: 21 [640/5446 (12%)],\tAccuracy: 100.0%,  \t Loss: 0.0734\n",
      "Epoch: 21 [768/5446 (14%)],\tAccuracy: 99.2%,  \t Loss: 0.0746\n",
      "Epoch: 21 [896/5446 (16%)],\tAccuracy: 99.2%,  \t Loss: 0.0525\n",
      "Epoch: 21 [1024/5446 (19%)],\tAccuracy: 100.0%,  \t Loss: 0.0735\n",
      "Epoch: 21 [1152/5446 (21%)],\tAccuracy: 99.2%,  \t Loss: 0.0876\n",
      "Epoch: 21 [1280/5446 (24%)],\tAccuracy: 100.0%,  \t Loss: 0.0618\n",
      "Epoch: 21 [1408/5446 (26%)],\tAccuracy: 99.2%,  \t Loss: 0.1233\n",
      "Epoch: 21 [1536/5446 (28%)],\tAccuracy: 99.2%,  \t Loss: 0.0828\n",
      "Epoch: 21 [1664/5446 (31%)],\tAccuracy: 100.0%,  \t Loss: 0.0432\n",
      "Epoch: 21 [1792/5446 (33%)],\tAccuracy: 99.2%,  \t Loss: 0.1138\n",
      "Epoch: 21 [1920/5446 (35%)],\tAccuracy: 100.0%,  \t Loss: 0.0572\n",
      "Epoch: 21 [2048/5446 (38%)],\tAccuracy: 100.0%,  \t Loss: 0.0557\n",
      "Epoch: 21 [2176/5446 (40%)],\tAccuracy: 100.0%,  \t Loss: 0.0563\n",
      "Epoch: 21 [2304/5446 (42%)],\tAccuracy: 100.0%,  \t Loss: 0.0534\n",
      "Epoch: 21 [2432/5446 (45%)],\tAccuracy: 100.0%,  \t Loss: 0.0713\n",
      "Epoch: 21 [2560/5446 (47%)],\tAccuracy: 97.7%,  \t Loss: 0.1620\n",
      "Epoch: 21 [2688/5446 (49%)],\tAccuracy: 99.2%,  \t Loss: 0.0642\n",
      "Epoch: 21 [2816/5446 (52%)],\tAccuracy: 100.0%,  \t Loss: 0.0504\n",
      "Epoch: 21 [2944/5446 (54%)],\tAccuracy: 100.0%,  \t Loss: 0.0582\n",
      "Epoch: 21 [3072/5446 (56%)],\tAccuracy: 98.4%,  \t Loss: 0.1031\n",
      "Epoch: 21 [3200/5446 (59%)],\tAccuracy: 100.0%,  \t Loss: 0.0690\n",
      "Epoch: 21 [3328/5446 (61%)],\tAccuracy: 99.2%,  \t Loss: 0.0905\n",
      "Epoch: 21 [3456/5446 (63%)],\tAccuracy: 100.0%,  \t Loss: 0.0770\n",
      "Epoch: 21 [3584/5446 (66%)],\tAccuracy: 98.4%,  \t Loss: 0.1223\n",
      "Epoch: 21 [3712/5446 (68%)],\tAccuracy: 100.0%,  \t Loss: 0.0650\n",
      "Epoch: 21 [3840/5446 (71%)],\tAccuracy: 100.0%,  \t Loss: 0.0662\n",
      "Epoch: 21 [3968/5446 (73%)],\tAccuracy: 98.4%,  \t Loss: 0.1536\n",
      "Epoch: 21 [4096/5446 (75%)],\tAccuracy: 100.0%,  \t Loss: 0.0457\n",
      "Epoch: 21 [4224/5446 (78%)],\tAccuracy: 99.2%,  \t Loss: 0.0673\n",
      "Epoch: 21 [4352/5446 (80%)],\tAccuracy: 100.0%,  \t Loss: 0.0428\n",
      "Epoch: 21 [4480/5446 (82%)],\tAccuracy: 100.0%,  \t Loss: 0.0813\n",
      "Epoch: 21 [4608/5446 (85%)],\tAccuracy: 100.0%,  \t Loss: 0.0723\n",
      "Epoch: 21 [4736/5446 (87%)],\tAccuracy: 100.0%,  \t Loss: 0.0603\n",
      "Epoch: 21 [4864/5446 (89%)],\tAccuracy: 100.0%,  \t Loss: 0.0807\n",
      "Epoch: 21 [4992/5446 (92%)],\tAccuracy: 98.4%,  \t Loss: 0.1301\n",
      "Epoch: 21 [5120/5446 (94%)],\tAccuracy: 100.0%,  \t Loss: 0.0427\n",
      "Epoch: 21 [5248/5446 (96%)],\tAccuracy: 100.0%,  \t Loss: 0.0770\n",
      "Epoch: 21 [5376/5446 (99%)],\tAccuracy: 100.0%,  \t Loss: 0.0764\n",
      "Epoch: 21 [5446/5446 (100%)],\tAccuracy: 100.0%,  \t Loss: 0.0427\n",
      "loss_val: 0.7445489317178726 616\n",
      "acc_val: 589 616\n",
      "Validation ==================================================\n",
      "Avg loss (val): 0.0012\n",
      "Avg acc (val): 0.9562\n",
      "\n",
      "Epoch: 22 [128/5446 (2%)],\tAccuracy: 100.0%,  \t Loss: 0.0333\n",
      "Epoch: 22 [256/5446 (5%)],\tAccuracy: 100.0%,  \t Loss: 0.0674\n",
      "Epoch: 22 [384/5446 (7%)],\tAccuracy: 96.9%,  \t Loss: 0.1863\n",
      "Epoch: 22 [512/5446 (9%)],\tAccuracy: 99.2%,  \t Loss: 0.0573\n",
      "Epoch: 22 [640/5446 (12%)],\tAccuracy: 100.0%,  \t Loss: 0.0475\n",
      "Epoch: 22 [768/5446 (14%)],\tAccuracy: 100.0%,  \t Loss: 0.0431\n",
      "Epoch: 22 [896/5446 (16%)],\tAccuracy: 99.2%,  \t Loss: 0.1166\n",
      "Epoch: 22 [1024/5446 (19%)],\tAccuracy: 99.2%,  \t Loss: 0.0818\n",
      "Epoch: 22 [1152/5446 (21%)],\tAccuracy: 98.4%,  \t Loss: 0.1050\n",
      "Epoch: 22 [1280/5446 (24%)],\tAccuracy: 99.2%,  \t Loss: 0.0915\n",
      "Epoch: 22 [1408/5446 (26%)],\tAccuracy: 99.2%,  \t Loss: 0.0922\n",
      "Epoch: 22 [1536/5446 (28%)],\tAccuracy: 100.0%,  \t Loss: 0.0587\n",
      "Epoch: 22 [1664/5446 (31%)],\tAccuracy: 100.0%,  \t Loss: 0.0871\n",
      "Epoch: 22 [1792/5446 (33%)],\tAccuracy: 100.0%,  \t Loss: 0.0489\n",
      "Epoch: 22 [1920/5446 (35%)],\tAccuracy: 100.0%,  \t Loss: 0.0448\n",
      "Epoch: 22 [2048/5446 (38%)],\tAccuracy: 100.0%,  \t Loss: 0.0660\n",
      "Epoch: 22 [2176/5446 (40%)],\tAccuracy: 100.0%,  \t Loss: 0.0558\n",
      "Epoch: 22 [2304/5446 (42%)],\tAccuracy: 100.0%,  \t Loss: 0.0758\n",
      "Epoch: 22 [2432/5446 (45%)],\tAccuracy: 100.0%,  \t Loss: 0.0502\n",
      "Epoch: 22 [2560/5446 (47%)],\tAccuracy: 99.2%,  \t Loss: 0.0879\n",
      "Epoch: 22 [2688/5446 (49%)],\tAccuracy: 96.9%,  \t Loss: 0.2003\n",
      "Epoch: 22 [2816/5446 (52%)],\tAccuracy: 100.0%,  \t Loss: 0.0406\n",
      "Epoch: 22 [2944/5446 (54%)],\tAccuracy: 99.2%,  \t Loss: 0.0691\n",
      "Epoch: 22 [3072/5446 (56%)],\tAccuracy: 100.0%,  \t Loss: 0.0565\n",
      "Epoch: 22 [3200/5446 (59%)],\tAccuracy: 100.0%,  \t Loss: 0.0513\n",
      "Epoch: 22 [3328/5446 (61%)],\tAccuracy: 100.0%,  \t Loss: 0.0531\n",
      "Epoch: 22 [3456/5446 (63%)],\tAccuracy: 100.0%,  \t Loss: 0.0579\n",
      "Epoch: 22 [3584/5446 (66%)],\tAccuracy: 100.0%,  \t Loss: 0.0929\n",
      "Epoch: 22 [3712/5446 (68%)],\tAccuracy: 100.0%,  \t Loss: 0.0476\n",
      "Epoch: 22 [3840/5446 (71%)],\tAccuracy: 99.2%,  \t Loss: 0.0905\n",
      "Epoch: 22 [3968/5446 (73%)],\tAccuracy: 99.2%,  \t Loss: 0.1268\n",
      "Epoch: 22 [4096/5446 (75%)],\tAccuracy: 100.0%,  \t Loss: 0.0595\n",
      "Epoch: 22 [4224/5446 (78%)],\tAccuracy: 99.2%,  \t Loss: 0.0996\n",
      "Epoch: 22 [4352/5446 (80%)],\tAccuracy: 98.4%,  \t Loss: 0.1262\n",
      "Epoch: 22 [4480/5446 (82%)],\tAccuracy: 100.0%,  \t Loss: 0.0511\n",
      "Epoch: 22 [4608/5446 (85%)],\tAccuracy: 100.0%,  \t Loss: 0.0281\n",
      "Epoch: 22 [4736/5446 (87%)],\tAccuracy: 99.2%,  \t Loss: 0.0836\n",
      "Epoch: 22 [4864/5446 (89%)],\tAccuracy: 99.2%,  \t Loss: 0.0992\n",
      "Epoch: 22 [4992/5446 (92%)],\tAccuracy: 100.0%,  \t Loss: 0.0578\n",
      "Epoch: 22 [5120/5446 (94%)],\tAccuracy: 100.0%,  \t Loss: 0.0518\n",
      "Epoch: 22 [5248/5446 (96%)],\tAccuracy: 99.2%,  \t Loss: 0.0710\n",
      "Epoch: 22 [5376/5446 (99%)],\tAccuracy: 100.0%,  \t Loss: 0.0495\n",
      "Epoch: 22 [5446/5446 (100%)],\tAccuracy: 100.0%,  \t Loss: 0.0727\n",
      "loss_val: 0.7682129368185997 616\n",
      "acc_val: 586 616\n",
      "Validation ==================================================\n",
      "Avg loss (val): 0.0012\n",
      "Avg acc (val): 0.9513\n",
      "\n",
      "Epoch: 23 [128/5446 (2%)],\tAccuracy: 99.2%,  \t Loss: 0.0699\n",
      "Epoch: 23 [256/5446 (5%)],\tAccuracy: 100.0%,  \t Loss: 0.0371\n",
      "Epoch: 23 [384/5446 (7%)],\tAccuracy: 99.2%,  \t Loss: 0.0853\n",
      "Epoch: 23 [512/5446 (9%)],\tAccuracy: 100.0%,  \t Loss: 0.0463\n",
      "Epoch: 23 [640/5446 (12%)],\tAccuracy: 100.0%,  \t Loss: 0.0516\n",
      "Epoch: 23 [768/5446 (14%)],\tAccuracy: 100.0%,  \t Loss: 0.0710\n",
      "Epoch: 23 [896/5446 (16%)],\tAccuracy: 100.0%,  \t Loss: 0.0608\n",
      "Epoch: 23 [1024/5446 (19%)],\tAccuracy: 100.0%,  \t Loss: 0.0359\n",
      "Epoch: 23 [1152/5446 (21%)],\tAccuracy: 99.2%,  \t Loss: 0.1025\n",
      "Epoch: 23 [1280/5446 (24%)],\tAccuracy: 100.0%,  \t Loss: 0.0470\n",
      "Epoch: 23 [1408/5446 (26%)],\tAccuracy: 100.0%,  \t Loss: 0.0301\n",
      "Epoch: 23 [1536/5446 (28%)],\tAccuracy: 100.0%,  \t Loss: 0.0565\n",
      "Epoch: 23 [1664/5446 (31%)],\tAccuracy: 100.0%,  \t Loss: 0.0306\n",
      "Epoch: 23 [1792/5446 (33%)],\tAccuracy: 99.2%,  \t Loss: 0.0492\n",
      "Epoch: 23 [1920/5446 (35%)],\tAccuracy: 100.0%,  \t Loss: 0.0348\n",
      "Epoch: 23 [2048/5446 (38%)],\tAccuracy: 99.2%,  \t Loss: 0.1242\n",
      "Epoch: 23 [2176/5446 (40%)],\tAccuracy: 98.4%,  \t Loss: 0.1353\n",
      "Epoch: 23 [2304/5446 (42%)],\tAccuracy: 100.0%,  \t Loss: 0.0281\n",
      "Epoch: 23 [2432/5446 (45%)],\tAccuracy: 100.0%,  \t Loss: 0.0253\n",
      "Epoch: 23 [2560/5446 (47%)],\tAccuracy: 100.0%,  \t Loss: 0.0705\n",
      "Epoch: 23 [2688/5446 (49%)],\tAccuracy: 100.0%,  \t Loss: 0.0514\n",
      "Epoch: 23 [2816/5446 (52%)],\tAccuracy: 100.0%,  \t Loss: 0.0845\n",
      "Epoch: 23 [2944/5446 (54%)],\tAccuracy: 99.2%,  \t Loss: 0.1215\n",
      "Epoch: 23 [3072/5446 (56%)],\tAccuracy: 99.2%,  \t Loss: 0.0623\n",
      "Epoch: 23 [3200/5446 (59%)],\tAccuracy: 100.0%,  \t Loss: 0.0775\n",
      "Epoch: 23 [3328/5446 (61%)],\tAccuracy: 100.0%,  \t Loss: 0.0411\n",
      "Epoch: 23 [3456/5446 (63%)],\tAccuracy: 99.2%,  \t Loss: 0.1147\n",
      "Epoch: 23 [3584/5446 (66%)],\tAccuracy: 100.0%,  \t Loss: 0.0409\n",
      "Epoch: 23 [3712/5446 (68%)],\tAccuracy: 100.0%,  \t Loss: 0.0452\n",
      "Epoch: 23 [3840/5446 (71%)],\tAccuracy: 100.0%,  \t Loss: 0.0661\n",
      "Epoch: 23 [3968/5446 (73%)],\tAccuracy: 100.0%,  \t Loss: 0.0610\n",
      "Epoch: 23 [4096/5446 (75%)],\tAccuracy: 99.2%,  \t Loss: 0.0558\n",
      "Epoch: 23 [4224/5446 (78%)],\tAccuracy: 99.2%,  \t Loss: 0.0728\n",
      "Epoch: 23 [4352/5446 (80%)],\tAccuracy: 99.2%,  \t Loss: 0.0536\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23 [4480/5446 (82%)],\tAccuracy: 99.2%,  \t Loss: 0.0631\n",
      "Epoch: 23 [4608/5446 (85%)],\tAccuracy: 98.4%,  \t Loss: 0.1219\n",
      "Epoch: 23 [4736/5446 (87%)],\tAccuracy: 100.0%,  \t Loss: 0.0732\n",
      "Epoch: 23 [4864/5446 (89%)],\tAccuracy: 99.2%,  \t Loss: 0.0995\n",
      "Epoch: 23 [4992/5446 (92%)],\tAccuracy: 99.2%,  \t Loss: 0.0647\n",
      "Epoch: 23 [5120/5446 (94%)],\tAccuracy: 100.0%,  \t Loss: 0.0343\n",
      "Epoch: 23 [5248/5446 (96%)],\tAccuracy: 99.2%,  \t Loss: 0.0875\n",
      "Epoch: 23 [5376/5446 (99%)],\tAccuracy: 99.2%,  \t Loss: 0.1476\n",
      "Epoch: 23 [5446/5446 (100%)],\tAccuracy: 100.0%,  \t Loss: 0.1204\n",
      "loss_val: 0.7434348613023758 616\n",
      "acc_val: 587 616\n",
      "Validation ==================================================\n",
      "Avg loss (val): 0.0012\n",
      "Avg acc (val): 0.9529\n",
      "\n",
      "Epoch: 24 [128/5446 (2%)],\tAccuracy: 100.0%,  \t Loss: 0.0316\n",
      "Epoch: 24 [256/5446 (5%)],\tAccuracy: 100.0%,  \t Loss: 0.0542\n",
      "Epoch: 24 [384/5446 (7%)],\tAccuracy: 100.0%,  \t Loss: 0.0381\n",
      "Epoch: 24 [512/5446 (9%)],\tAccuracy: 100.0%,  \t Loss: 0.0249\n",
      "Epoch: 24 [640/5446 (12%)],\tAccuracy: 99.2%,  \t Loss: 0.0680\n",
      "Epoch: 24 [768/5446 (14%)],\tAccuracy: 100.0%,  \t Loss: 0.0332\n",
      "Epoch: 24 [896/5446 (16%)],\tAccuracy: 100.0%,  \t Loss: 0.0691\n",
      "Epoch: 24 [1024/5446 (19%)],\tAccuracy: 99.2%,  \t Loss: 0.0779\n",
      "Epoch: 24 [1152/5446 (21%)],\tAccuracy: 99.2%,  \t Loss: 0.0652\n",
      "Epoch: 24 [1280/5446 (24%)],\tAccuracy: 100.0%,  \t Loss: 0.0572\n",
      "Epoch: 24 [1408/5446 (26%)],\tAccuracy: 100.0%,  \t Loss: 0.0517\n",
      "Epoch: 24 [1536/5446 (28%)],\tAccuracy: 99.2%,  \t Loss: 0.0798\n",
      "Epoch: 24 [1664/5446 (31%)],\tAccuracy: 100.0%,  \t Loss: 0.0299\n",
      "Epoch: 24 [1792/5446 (33%)],\tAccuracy: 100.0%,  \t Loss: 0.0440\n",
      "Epoch: 24 [1920/5446 (35%)],\tAccuracy: 100.0%,  \t Loss: 0.0378\n",
      "Epoch: 24 [2048/5446 (38%)],\tAccuracy: 100.0%,  \t Loss: 0.0129\n",
      "Epoch: 24 [2176/5446 (40%)],\tAccuracy: 100.0%,  \t Loss: 0.0386\n",
      "Epoch: 24 [2304/5446 (42%)],\tAccuracy: 100.0%,  \t Loss: 0.0488\n",
      "Epoch: 24 [2432/5446 (45%)],\tAccuracy: 100.0%,  \t Loss: 0.0560\n",
      "Epoch: 24 [2560/5446 (47%)],\tAccuracy: 100.0%,  \t Loss: 0.0630\n",
      "Epoch: 24 [2688/5446 (49%)],\tAccuracy: 100.0%,  \t Loss: 0.0498\n",
      "Epoch: 24 [2816/5446 (52%)],\tAccuracy: 100.0%,  \t Loss: 0.0302\n",
      "Epoch: 24 [2944/5446 (54%)],\tAccuracy: 100.0%,  \t Loss: 0.0779\n",
      "Epoch: 24 [3072/5446 (56%)],\tAccuracy: 100.0%,  \t Loss: 0.0221\n",
      "Epoch: 24 [3200/5446 (59%)],\tAccuracy: 100.0%,  \t Loss: 0.0413\n",
      "Epoch: 24 [3328/5446 (61%)],\tAccuracy: 100.0%,  \t Loss: 0.0428\n",
      "Epoch: 24 [3456/5446 (63%)],\tAccuracy: 100.0%,  \t Loss: 0.0505\n",
      "Epoch: 24 [3584/5446 (66%)],\tAccuracy: 100.0%,  \t Loss: 0.0537\n",
      "Epoch: 24 [3712/5446 (68%)],\tAccuracy: 100.0%,  \t Loss: 0.0393\n",
      "Epoch: 24 [3840/5446 (71%)],\tAccuracy: 100.0%,  \t Loss: 0.0368\n",
      "Epoch: 24 [3968/5446 (73%)],\tAccuracy: 100.0%,  \t Loss: 0.0266\n",
      "Epoch: 24 [4096/5446 (75%)],\tAccuracy: 99.2%,  \t Loss: 0.0646\n",
      "Epoch: 24 [4224/5446 (78%)],\tAccuracy: 99.2%,  \t Loss: 0.0609\n",
      "Epoch: 24 [4352/5446 (80%)],\tAccuracy: 99.2%,  \t Loss: 0.1067\n",
      "Epoch: 24 [4480/5446 (82%)],\tAccuracy: 100.0%,  \t Loss: 0.0513\n",
      "Epoch: 24 [4608/5446 (85%)],\tAccuracy: 100.0%,  \t Loss: 0.0258\n",
      "Epoch: 24 [4736/5446 (87%)],\tAccuracy: 100.0%,  \t Loss: 0.0297\n",
      "Epoch: 24 [4864/5446 (89%)],\tAccuracy: 99.2%,  \t Loss: 0.0916\n",
      "Epoch: 24 [4992/5446 (92%)],\tAccuracy: 100.0%,  \t Loss: 0.0521\n",
      "Epoch: 24 [5120/5446 (94%)],\tAccuracy: 98.4%,  \t Loss: 0.0642\n",
      "Epoch: 24 [5248/5446 (96%)],\tAccuracy: 100.0%,  \t Loss: 0.0493\n",
      "Epoch: 24 [5376/5446 (99%)],\tAccuracy: 99.2%,  \t Loss: 0.0701\n",
      "Epoch: 24 [5446/5446 (100%)],\tAccuracy: 100.0%,  \t Loss: 0.0234\n",
      "loss_val: 0.7783210352063179 616\n",
      "acc_val: 588 616\n",
      "Validation ==================================================\n",
      "Avg loss (val): 0.0013\n",
      "Avg acc (val): 0.9545\n",
      "\n",
      "Epoch: 25 [128/5446 (2%)],\tAccuracy: 100.0%,  \t Loss: 0.0656\n",
      "Epoch: 25 [256/5446 (5%)],\tAccuracy: 99.2%,  \t Loss: 0.1152\n",
      "Epoch: 25 [384/5446 (7%)],\tAccuracy: 100.0%,  \t Loss: 0.0659\n",
      "Epoch: 25 [512/5446 (9%)],\tAccuracy: 100.0%,  \t Loss: 0.0269\n",
      "Epoch: 25 [640/5446 (12%)],\tAccuracy: 100.0%,  \t Loss: 0.0322\n",
      "Epoch: 25 [768/5446 (14%)],\tAccuracy: 100.0%,  \t Loss: 0.0465\n",
      "Epoch: 25 [896/5446 (16%)],\tAccuracy: 99.2%,  \t Loss: 0.0728\n",
      "Epoch: 25 [1024/5446 (19%)],\tAccuracy: 100.0%,  \t Loss: 0.0351\n",
      "Epoch: 25 [1152/5446 (21%)],\tAccuracy: 100.0%,  \t Loss: 0.0419\n",
      "Epoch: 25 [1280/5446 (24%)],\tAccuracy: 100.0%,  \t Loss: 0.0144\n",
      "Epoch: 25 [1408/5446 (26%)],\tAccuracy: 100.0%,  \t Loss: 0.0412\n",
      "Epoch: 25 [1536/5446 (28%)],\tAccuracy: 99.2%,  \t Loss: 0.0676\n",
      "Epoch: 25 [1664/5446 (31%)],\tAccuracy: 100.0%,  \t Loss: 0.0473\n",
      "Epoch: 25 [1792/5446 (33%)],\tAccuracy: 100.0%,  \t Loss: 0.0269\n",
      "Epoch: 25 [1920/5446 (35%)],\tAccuracy: 100.0%,  \t Loss: 0.0636\n",
      "Epoch: 25 [2048/5446 (38%)],\tAccuracy: 100.0%,  \t Loss: 0.0218\n",
      "Epoch: 25 [2176/5446 (40%)],\tAccuracy: 100.0%,  \t Loss: 0.0332\n",
      "Epoch: 25 [2304/5446 (42%)],\tAccuracy: 100.0%,  \t Loss: 0.0225\n",
      "Epoch: 25 [2432/5446 (45%)],\tAccuracy: 100.0%,  \t Loss: 0.0630\n",
      "Epoch: 25 [2560/5446 (47%)],\tAccuracy: 100.0%,  \t Loss: 0.0402\n",
      "Epoch: 25 [2688/5446 (49%)],\tAccuracy: 100.0%,  \t Loss: 0.0624\n",
      "Epoch: 25 [2816/5446 (52%)],\tAccuracy: 99.2%,  \t Loss: 0.0600\n",
      "Epoch: 25 [2944/5446 (54%)],\tAccuracy: 100.0%,  \t Loss: 0.0503\n",
      "Epoch: 25 [3072/5446 (56%)],\tAccuracy: 100.0%,  \t Loss: 0.0390\n",
      "Epoch: 25 [3200/5446 (59%)],\tAccuracy: 100.0%,  \t Loss: 0.0215\n",
      "Epoch: 25 [3328/5446 (61%)],\tAccuracy: 100.0%,  \t Loss: 0.0409\n",
      "Epoch: 25 [3456/5446 (63%)],\tAccuracy: 100.0%,  \t Loss: 0.0742\n",
      "Epoch: 25 [3584/5446 (66%)],\tAccuracy: 99.2%,  \t Loss: 0.0707\n",
      "Epoch: 25 [3712/5446 (68%)],\tAccuracy: 100.0%,  \t Loss: 0.0483\n",
      "Epoch: 25 [3840/5446 (71%)],\tAccuracy: 100.0%,  \t Loss: 0.0607\n",
      "Epoch: 25 [3968/5446 (73%)],\tAccuracy: 100.0%,  \t Loss: 0.0319\n",
      "Epoch: 25 [4096/5446 (75%)],\tAccuracy: 100.0%,  \t Loss: 0.0585\n",
      "Epoch: 25 [4224/5446 (78%)],\tAccuracy: 100.0%,  \t Loss: 0.0471\n",
      "Epoch: 25 [4352/5446 (80%)],\tAccuracy: 100.0%,  \t Loss: 0.0504\n",
      "Epoch: 25 [4480/5446 (82%)],\tAccuracy: 100.0%,  \t Loss: 0.0278\n",
      "Epoch: 25 [4608/5446 (85%)],\tAccuracy: 100.0%,  \t Loss: 0.0409\n",
      "Epoch: 25 [4736/5446 (87%)],\tAccuracy: 100.0%,  \t Loss: 0.0588\n",
      "Epoch: 25 [4864/5446 (89%)],\tAccuracy: 100.0%,  \t Loss: 0.0315\n",
      "Epoch: 25 [4992/5446 (92%)],\tAccuracy: 99.2%,  \t Loss: 0.0490\n",
      "Epoch: 25 [5120/5446 (94%)],\tAccuracy: 100.0%,  \t Loss: 0.0306\n",
      "Epoch: 25 [5248/5446 (96%)],\tAccuracy: 100.0%,  \t Loss: 0.0462\n",
      "Epoch: 25 [5376/5446 (99%)],\tAccuracy: 100.0%,  \t Loss: 0.0221\n",
      "Epoch: 25 [5446/5446 (100%)],\tAccuracy: 100.0%,  \t Loss: 0.0516\n",
      "loss_val: 0.7682136669754982 616\n",
      "acc_val: 585 616\n",
      "Validation ==================================================\n",
      "Avg loss (val): 0.0012\n",
      "Avg acc (val): 0.9497\n",
      "\n",
      "Epoch: 26 [128/5446 (2%)],\tAccuracy: 100.0%,  \t Loss: 0.0217\n",
      "Epoch: 26 [256/5446 (5%)],\tAccuracy: 100.0%,  \t Loss: 0.0673\n",
      "Epoch: 26 [384/5446 (7%)],\tAccuracy: 98.4%,  \t Loss: 0.0767\n",
      "Epoch: 26 [512/5446 (9%)],\tAccuracy: 99.2%,  \t Loss: 0.0554\n",
      "Epoch: 26 [640/5446 (12%)],\tAccuracy: 100.0%,  \t Loss: 0.0381\n",
      "Epoch: 26 [768/5446 (14%)],\tAccuracy: 100.0%,  \t Loss: 0.0186\n",
      "Epoch: 26 [896/5446 (16%)],\tAccuracy: 100.0%,  \t Loss: 0.0338\n",
      "Epoch: 26 [1024/5446 (19%)],\tAccuracy: 100.0%,  \t Loss: 0.0389\n",
      "Epoch: 26 [1152/5446 (21%)],\tAccuracy: 99.2%,  \t Loss: 0.0681\n",
      "Epoch: 26 [1280/5446 (24%)],\tAccuracy: 100.0%,  \t Loss: 0.0370\n",
      "Epoch: 26 [1408/5446 (26%)],\tAccuracy: 100.0%,  \t Loss: 0.0291\n",
      "Epoch: 26 [1536/5446 (28%)],\tAccuracy: 100.0%,  \t Loss: 0.0231\n",
      "Epoch: 26 [1664/5446 (31%)],\tAccuracy: 100.0%,  \t Loss: 0.0391\n",
      "Epoch: 26 [1792/5446 (33%)],\tAccuracy: 100.0%,  \t Loss: 0.0614\n",
      "Epoch: 26 [1920/5446 (35%)],\tAccuracy: 100.0%,  \t Loss: 0.0472\n",
      "Epoch: 26 [2048/5446 (38%)],\tAccuracy: 100.0%,  \t Loss: 0.0216\n",
      "Epoch: 26 [2176/5446 (40%)],\tAccuracy: 100.0%,  \t Loss: 0.0343\n",
      "Epoch: 26 [2304/5446 (42%)],\tAccuracy: 97.7%,  \t Loss: 0.1049\n",
      "Epoch: 26 [2432/5446 (45%)],\tAccuracy: 99.2%,  \t Loss: 0.0625\n",
      "Epoch: 26 [2560/5446 (47%)],\tAccuracy: 100.0%,  \t Loss: 0.0251\n",
      "Epoch: 26 [2688/5446 (49%)],\tAccuracy: 100.0%,  \t Loss: 0.0336\n",
      "Epoch: 26 [2816/5446 (52%)],\tAccuracy: 100.0%,  \t Loss: 0.0514\n",
      "Epoch: 26 [2944/5446 (54%)],\tAccuracy: 100.0%,  \t Loss: 0.0206\n",
      "Epoch: 26 [3072/5446 (56%)],\tAccuracy: 100.0%,  \t Loss: 0.0140\n",
      "Epoch: 26 [3200/5446 (59%)],\tAccuracy: 100.0%,  \t Loss: 0.0271\n",
      "Epoch: 26 [3328/5446 (61%)],\tAccuracy: 99.2%,  \t Loss: 0.0490\n",
      "Epoch: 26 [3456/5446 (63%)],\tAccuracy: 99.2%,  \t Loss: 0.0644\n",
      "Epoch: 26 [3584/5446 (66%)],\tAccuracy: 100.0%,  \t Loss: 0.0799\n",
      "Epoch: 26 [3712/5446 (68%)],\tAccuracy: 100.0%,  \t Loss: 0.0239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26 [3840/5446 (71%)],\tAccuracy: 100.0%,  \t Loss: 0.0333\n",
      "Epoch: 26 [3968/5446 (73%)],\tAccuracy: 99.2%,  \t Loss: 0.1099\n",
      "Epoch: 26 [4096/5446 (75%)],\tAccuracy: 99.2%,  \t Loss: 0.1361\n",
      "Epoch: 26 [4224/5446 (78%)],\tAccuracy: 99.2%,  \t Loss: 0.0761\n",
      "Epoch: 26 [4352/5446 (80%)],\tAccuracy: 99.2%,  \t Loss: 0.1167\n",
      "Epoch: 26 [4480/5446 (82%)],\tAccuracy: 100.0%,  \t Loss: 0.0567\n",
      "Epoch: 26 [4608/5446 (85%)],\tAccuracy: 100.0%,  \t Loss: 0.0285\n",
      "Epoch: 26 [4736/5446 (87%)],\tAccuracy: 100.0%,  \t Loss: 0.0434\n",
      "Epoch: 26 [4864/5446 (89%)],\tAccuracy: 100.0%,  \t Loss: 0.0361\n",
      "Epoch: 26 [4992/5446 (92%)],\tAccuracy: 100.0%,  \t Loss: 0.0384\n",
      "Epoch: 26 [5120/5446 (94%)],\tAccuracy: 100.0%,  \t Loss: 0.0288\n",
      "Epoch: 26 [5248/5446 (96%)],\tAccuracy: 100.0%,  \t Loss: 0.0363\n",
      "Epoch: 26 [5376/5446 (99%)],\tAccuracy: 100.0%,  \t Loss: 0.0302\n",
      "Epoch: 26 [5446/5446 (100%)],\tAccuracy: 100.0%,  \t Loss: 0.0198\n",
      "loss_val: 0.6847572922706604 616\n",
      "acc_val: 586 616\n",
      "Validation ==================================================\n",
      "Avg loss (val): 0.0011\n",
      "Avg acc (val): 0.9513\n",
      "\n",
      "Epoch: 27 [128/5446 (2%)],\tAccuracy: 99.2%,  \t Loss: 0.1145\n",
      "Epoch: 27 [256/5446 (5%)],\tAccuracy: 100.0%,  \t Loss: 0.0481\n",
      "Epoch: 27 [384/5446 (7%)],\tAccuracy: 100.0%,  \t Loss: 0.0484\n",
      "Epoch: 27 [512/5446 (9%)],\tAccuracy: 99.2%,  \t Loss: 0.0581\n",
      "Epoch: 27 [640/5446 (12%)],\tAccuracy: 99.2%,  \t Loss: 0.0570\n",
      "Epoch: 27 [768/5446 (14%)],\tAccuracy: 100.0%,  \t Loss: 0.0406\n",
      "Epoch: 27 [896/5446 (16%)],\tAccuracy: 100.0%,  \t Loss: 0.0235\n",
      "Epoch: 27 [1024/5446 (19%)],\tAccuracy: 99.2%,  \t Loss: 0.0758\n",
      "Epoch: 27 [1152/5446 (21%)],\tAccuracy: 100.0%,  \t Loss: 0.0383\n",
      "Epoch: 27 [1280/5446 (24%)],\tAccuracy: 100.0%,  \t Loss: 0.0315\n",
      "Epoch: 27 [1408/5446 (26%)],\tAccuracy: 100.0%,  \t Loss: 0.0216\n",
      "Epoch: 27 [1536/5446 (28%)],\tAccuracy: 98.4%,  \t Loss: 0.0603\n",
      "Epoch: 27 [1664/5446 (31%)],\tAccuracy: 100.0%,  \t Loss: 0.0362\n",
      "Epoch: 27 [1792/5446 (33%)],\tAccuracy: 100.0%,  \t Loss: 0.0296\n",
      "Epoch: 27 [1920/5446 (35%)],\tAccuracy: 100.0%,  \t Loss: 0.0364\n",
      "Epoch: 27 [2048/5446 (38%)],\tAccuracy: 100.0%,  \t Loss: 0.0339\n",
      "Epoch: 27 [2176/5446 (40%)],\tAccuracy: 100.0%,  \t Loss: 0.0412\n",
      "Epoch: 27 [2304/5446 (42%)],\tAccuracy: 99.2%,  \t Loss: 0.0867\n",
      "Epoch: 27 [2432/5446 (45%)],\tAccuracy: 99.2%,  \t Loss: 0.0670\n",
      "Epoch: 27 [2560/5446 (47%)],\tAccuracy: 100.0%,  \t Loss: 0.0251\n",
      "Epoch: 27 [2688/5446 (49%)],\tAccuracy: 100.0%,  \t Loss: 0.0400\n",
      "Epoch: 27 [2816/5446 (52%)],\tAccuracy: 100.0%,  \t Loss: 0.0360\n",
      "Epoch: 27 [2944/5446 (54%)],\tAccuracy: 100.0%,  \t Loss: 0.0268\n",
      "Epoch: 27 [3072/5446 (56%)],\tAccuracy: 100.0%,  \t Loss: 0.0274\n",
      "Epoch: 27 [3200/5446 (59%)],\tAccuracy: 100.0%,  \t Loss: 0.0397\n",
      "Epoch: 27 [3328/5446 (61%)],\tAccuracy: 100.0%,  \t Loss: 0.0410\n",
      "Epoch: 27 [3456/5446 (63%)],\tAccuracy: 99.2%,  \t Loss: 0.0494\n",
      "Epoch: 27 [3584/5446 (66%)],\tAccuracy: 100.0%,  \t Loss: 0.0319\n",
      "Epoch: 27 [3712/5446 (68%)],\tAccuracy: 100.0%,  \t Loss: 0.0393\n",
      "Epoch: 27 [3840/5446 (71%)],\tAccuracy: 100.0%,  \t Loss: 0.0599\n",
      "Epoch: 27 [3968/5446 (73%)],\tAccuracy: 100.0%,  \t Loss: 0.0237\n",
      "Epoch: 27 [4096/5446 (75%)],\tAccuracy: 100.0%,  \t Loss: 0.0360\n",
      "Epoch: 27 [4224/5446 (78%)],\tAccuracy: 100.0%,  \t Loss: 0.0270\n",
      "Epoch: 27 [4352/5446 (80%)],\tAccuracy: 100.0%,  \t Loss: 0.0449\n",
      "Epoch: 27 [4480/5446 (82%)],\tAccuracy: 99.2%,  \t Loss: 0.1011\n",
      "Epoch: 27 [4608/5446 (85%)],\tAccuracy: 100.0%,  \t Loss: 0.0256\n",
      "Epoch: 27 [4736/5446 (87%)],\tAccuracy: 100.0%,  \t Loss: 0.0408\n",
      "Epoch: 27 [4864/5446 (89%)],\tAccuracy: 100.0%,  \t Loss: 0.0413\n",
      "Epoch: 27 [4992/5446 (92%)],\tAccuracy: 99.2%,  \t Loss: 0.0551\n",
      "Epoch: 27 [5120/5446 (94%)],\tAccuracy: 99.2%,  \t Loss: 0.0681\n",
      "Epoch: 27 [5248/5446 (96%)],\tAccuracy: 100.0%,  \t Loss: 0.0171\n",
      "Epoch: 27 [5376/5446 (99%)],\tAccuracy: 100.0%,  \t Loss: 0.0238\n",
      "Epoch: 27 [5446/5446 (100%)],\tAccuracy: 100.0%,  \t Loss: 0.0198\n",
      "loss_val: 0.6937929466366768 616\n",
      "acc_val: 588 616\n",
      "Validation ==================================================\n",
      "Avg loss (val): 0.0011\n",
      "Avg acc (val): 0.9545\n",
      "\n",
      "Epoch: 28 [128/5446 (2%)],\tAccuracy: 100.0%,  \t Loss: 0.0568\n",
      "Epoch: 28 [256/5446 (5%)],\tAccuracy: 100.0%,  \t Loss: 0.0294\n",
      "Epoch: 28 [384/5446 (7%)],\tAccuracy: 100.0%,  \t Loss: 0.0731\n",
      "Epoch: 28 [512/5446 (9%)],\tAccuracy: 100.0%,  \t Loss: 0.0248\n",
      "Epoch: 28 [640/5446 (12%)],\tAccuracy: 100.0%,  \t Loss: 0.0367\n",
      "Epoch: 28 [768/5446 (14%)],\tAccuracy: 100.0%,  \t Loss: 0.0462\n",
      "Epoch: 28 [896/5446 (16%)],\tAccuracy: 99.2%,  \t Loss: 0.0577\n",
      "Epoch: 28 [1024/5446 (19%)],\tAccuracy: 100.0%,  \t Loss: 0.0246\n",
      "Epoch: 28 [1152/5446 (21%)],\tAccuracy: 100.0%,  \t Loss: 0.0180\n",
      "Epoch: 28 [1280/5446 (24%)],\tAccuracy: 100.0%,  \t Loss: 0.0176\n",
      "Epoch: 28 [1408/5446 (26%)],\tAccuracy: 99.2%,  \t Loss: 0.0502\n",
      "Epoch: 28 [1536/5446 (28%)],\tAccuracy: 99.2%,  \t Loss: 0.0692\n",
      "Epoch: 28 [1664/5446 (31%)],\tAccuracy: 100.0%,  \t Loss: 0.0226\n",
      "Epoch: 28 [1792/5446 (33%)],\tAccuracy: 100.0%,  \t Loss: 0.0208\n",
      "Epoch: 28 [1920/5446 (35%)],\tAccuracy: 100.0%,  \t Loss: 0.0277\n",
      "Epoch: 28 [2048/5446 (38%)],\tAccuracy: 100.0%,  \t Loss: 0.0344\n",
      "Epoch: 28 [2176/5446 (40%)],\tAccuracy: 99.2%,  \t Loss: 0.1008\n",
      "Epoch: 28 [2304/5446 (42%)],\tAccuracy: 100.0%,  \t Loss: 0.0315\n",
      "Epoch: 28 [2432/5446 (45%)],\tAccuracy: 99.2%,  \t Loss: 0.0452\n",
      "Epoch: 28 [2560/5446 (47%)],\tAccuracy: 100.0%,  \t Loss: 0.0375\n",
      "Epoch: 28 [2688/5446 (49%)],\tAccuracy: 100.0%,  \t Loss: 0.0186\n",
      "Epoch: 28 [2816/5446 (52%)],\tAccuracy: 99.2%,  \t Loss: 0.0954\n",
      "Epoch: 28 [2944/5446 (54%)],\tAccuracy: 99.2%,  \t Loss: 0.0534\n",
      "Epoch: 28 [3072/5446 (56%)],\tAccuracy: 100.0%,  \t Loss: 0.0338\n",
      "Epoch: 28 [3200/5446 (59%)],\tAccuracy: 100.0%,  \t Loss: 0.0409\n",
      "Epoch: 28 [3328/5446 (61%)],\tAccuracy: 100.0%,  \t Loss: 0.0168\n",
      "Epoch: 28 [3456/5446 (63%)],\tAccuracy: 100.0%,  \t Loss: 0.0301\n",
      "Epoch: 28 [3584/5446 (66%)],\tAccuracy: 100.0%,  \t Loss: 0.0342\n",
      "Epoch: 28 [3712/5446 (68%)],\tAccuracy: 100.0%,  \t Loss: 0.0203\n",
      "Epoch: 28 [3840/5446 (71%)],\tAccuracy: 100.0%,  \t Loss: 0.0440\n",
      "Epoch: 28 [3968/5446 (73%)],\tAccuracy: 99.2%,  \t Loss: 0.1152\n",
      "Epoch: 28 [4096/5446 (75%)],\tAccuracy: 100.0%,  \t Loss: 0.0155\n",
      "Epoch: 28 [4224/5446 (78%)],\tAccuracy: 100.0%,  \t Loss: 0.0551\n",
      "Epoch: 28 [4352/5446 (80%)],\tAccuracy: 100.0%,  \t Loss: 0.0911\n",
      "Epoch: 28 [4480/5446 (82%)],\tAccuracy: 100.0%,  \t Loss: 0.0452\n",
      "Epoch: 28 [4608/5446 (85%)],\tAccuracy: 100.0%,  \t Loss: 0.0297\n",
      "Epoch: 28 [4736/5446 (87%)],\tAccuracy: 100.0%,  \t Loss: 0.0419\n",
      "Epoch: 28 [4864/5446 (89%)],\tAccuracy: 100.0%,  \t Loss: 0.0569\n",
      "Epoch: 28 [4992/5446 (92%)],\tAccuracy: 100.0%,  \t Loss: 0.0309\n",
      "Epoch: 28 [5120/5446 (94%)],\tAccuracy: 100.0%,  \t Loss: 0.0443\n",
      "Epoch: 28 [5248/5446 (96%)],\tAccuracy: 100.0%,  \t Loss: 0.0358\n",
      "Epoch: 28 [5376/5446 (99%)],\tAccuracy: 100.0%,  \t Loss: 0.0368\n",
      "Epoch: 28 [5446/5446 (100%)],\tAccuracy: 100.0%,  \t Loss: 0.0932\n",
      "loss_val: 0.7533770203590393 616\n",
      "acc_val: 584 616\n",
      "Validation ==================================================\n",
      "Avg loss (val): 0.0012\n",
      "Avg acc (val): 0.9481\n",
      "\n",
      "Epoch: 29 [128/5446 (2%)],\tAccuracy: 100.0%,  \t Loss: 0.0167\n",
      "Epoch: 29 [256/5446 (5%)],\tAccuracy: 100.0%,  \t Loss: 0.0429\n",
      "Epoch: 29 [384/5446 (7%)],\tAccuracy: 99.2%,  \t Loss: 0.0432\n",
      "Epoch: 29 [512/5446 (9%)],\tAccuracy: 100.0%,  \t Loss: 0.0122\n",
      "Epoch: 29 [640/5446 (12%)],\tAccuracy: 100.0%,  \t Loss: 0.0200\n",
      "Epoch: 29 [768/5446 (14%)],\tAccuracy: 100.0%,  \t Loss: 0.0520\n",
      "Epoch: 29 [896/5446 (16%)],\tAccuracy: 100.0%,  \t Loss: 0.0459\n",
      "Epoch: 29 [1024/5446 (19%)],\tAccuracy: 99.2%,  \t Loss: 0.0706\n",
      "Epoch: 29 [1152/5446 (21%)],\tAccuracy: 99.2%,  \t Loss: 0.0886\n",
      "Epoch: 29 [1280/5446 (24%)],\tAccuracy: 100.0%,  \t Loss: 0.0324\n",
      "Epoch: 29 [1408/5446 (26%)],\tAccuracy: 99.2%,  \t Loss: 0.0481\n",
      "Epoch: 29 [1536/5446 (28%)],\tAccuracy: 99.2%,  \t Loss: 0.0570\n",
      "Epoch: 29 [1664/5446 (31%)],\tAccuracy: 100.0%,  \t Loss: 0.0870\n",
      "Epoch: 29 [1792/5446 (33%)],\tAccuracy: 100.0%,  \t Loss: 0.0324\n",
      "Epoch: 29 [1920/5446 (35%)],\tAccuracy: 100.0%,  \t Loss: 0.0465\n",
      "Epoch: 29 [2048/5446 (38%)],\tAccuracy: 100.0%,  \t Loss: 0.0114\n",
      "Epoch: 29 [2176/5446 (40%)],\tAccuracy: 100.0%,  \t Loss: 0.0210\n",
      "Epoch: 29 [2304/5446 (42%)],\tAccuracy: 100.0%,  \t Loss: 0.0225\n",
      "Epoch: 29 [2432/5446 (45%)],\tAccuracy: 100.0%,  \t Loss: 0.0252\n",
      "Epoch: 29 [2560/5446 (47%)],\tAccuracy: 100.0%,  \t Loss: 0.0469\n",
      "Epoch: 29 [2688/5446 (49%)],\tAccuracy: 100.0%,  \t Loss: 0.0513\n",
      "Epoch: 29 [2816/5446 (52%)],\tAccuracy: 99.2%,  \t Loss: 0.0569\n",
      "Epoch: 29 [2944/5446 (54%)],\tAccuracy: 100.0%,  \t Loss: 0.0149\n",
      "Epoch: 29 [3072/5446 (56%)],\tAccuracy: 100.0%,  \t Loss: 0.0189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29 [3200/5446 (59%)],\tAccuracy: 100.0%,  \t Loss: 0.0378\n",
      "Epoch: 29 [3328/5446 (61%)],\tAccuracy: 99.2%,  \t Loss: 0.0707\n",
      "Epoch: 29 [3456/5446 (63%)],\tAccuracy: 100.0%,  \t Loss: 0.0248\n",
      "Epoch: 29 [3584/5446 (66%)],\tAccuracy: 99.2%,  \t Loss: 0.0478\n",
      "Epoch: 29 [3712/5446 (68%)],\tAccuracy: 100.0%,  \t Loss: 0.0377\n",
      "Epoch: 29 [3840/5446 (71%)],\tAccuracy: 100.0%,  \t Loss: 0.0293\n",
      "Epoch: 29 [3968/5446 (73%)],\tAccuracy: 100.0%,  \t Loss: 0.0191\n",
      "Epoch: 29 [4096/5446 (75%)],\tAccuracy: 100.0%,  \t Loss: 0.0383\n",
      "Epoch: 29 [4224/5446 (78%)],\tAccuracy: 100.0%,  \t Loss: 0.0260\n",
      "Epoch: 29 [4352/5446 (80%)],\tAccuracy: 100.0%,  \t Loss: 0.0247\n",
      "Epoch: 29 [4480/5446 (82%)],\tAccuracy: 100.0%,  \t Loss: 0.0395\n",
      "Epoch: 29 [4608/5446 (85%)],\tAccuracy: 100.0%,  \t Loss: 0.0187\n",
      "Epoch: 29 [4736/5446 (87%)],\tAccuracy: 100.0%,  \t Loss: 0.0253\n",
      "Epoch: 29 [4864/5446 (89%)],\tAccuracy: 100.0%,  \t Loss: 0.0328\n",
      "Epoch: 29 [4992/5446 (92%)],\tAccuracy: 99.2%,  \t Loss: 0.0672\n",
      "Epoch: 29 [5120/5446 (94%)],\tAccuracy: 100.0%,  \t Loss: 0.0266\n",
      "Epoch: 29 [5248/5446 (96%)],\tAccuracy: 99.2%,  \t Loss: 0.0710\n",
      "Epoch: 29 [5376/5446 (99%)],\tAccuracy: 100.0%,  \t Loss: 0.0201\n",
      "Epoch: 29 [5446/5446 (100%)],\tAccuracy: 100.0%,  \t Loss: 0.0313\n",
      "loss_val: 0.6887580640614033 616\n",
      "acc_val: 585 616\n",
      "Validation ==================================================\n",
      "Avg loss (val): 0.0011\n",
      "Avg acc (val): 0.9497\n",
      "\n",
      "Epoch: 30 [128/5446 (2%)],\tAccuracy: 100.0%,  \t Loss: 0.0327\n",
      "Epoch: 30 [256/5446 (5%)],\tAccuracy: 100.0%,  \t Loss: 0.0283\n",
      "Epoch: 30 [384/5446 (7%)],\tAccuracy: 100.0%,  \t Loss: 0.0227\n",
      "Epoch: 30 [512/5446 (9%)],\tAccuracy: 100.0%,  \t Loss: 0.0268\n",
      "Epoch: 30 [640/5446 (12%)],\tAccuracy: 100.0%,  \t Loss: 0.0284\n",
      "Epoch: 30 [768/5446 (14%)],\tAccuracy: 99.2%,  \t Loss: 0.0636\n",
      "Epoch: 30 [896/5446 (16%)],\tAccuracy: 100.0%,  \t Loss: 0.0115\n",
      "Epoch: 30 [1024/5446 (19%)],\tAccuracy: 99.2%,  \t Loss: 0.0500\n",
      "Epoch: 30 [1152/5446 (21%)],\tAccuracy: 100.0%,  \t Loss: 0.0434\n",
      "Epoch: 30 [1280/5446 (24%)],\tAccuracy: 100.0%,  \t Loss: 0.0190\n",
      "Epoch: 30 [1408/5446 (26%)],\tAccuracy: 100.0%,  \t Loss: 0.0307\n",
      "Epoch: 30 [1536/5446 (28%)],\tAccuracy: 99.2%,  \t Loss: 0.0525\n",
      "Epoch: 30 [1664/5446 (31%)],\tAccuracy: 100.0%,  \t Loss: 0.0135\n",
      "Epoch: 30 [1792/5446 (33%)],\tAccuracy: 100.0%,  \t Loss: 0.0435\n",
      "Epoch: 30 [1920/5446 (35%)],\tAccuracy: 100.0%,  \t Loss: 0.0133\n",
      "Epoch: 30 [2048/5446 (38%)],\tAccuracy: 100.0%,  \t Loss: 0.0279\n",
      "Epoch: 30 [2176/5446 (40%)],\tAccuracy: 100.0%,  \t Loss: 0.0247\n",
      "Epoch: 30 [2304/5446 (42%)],\tAccuracy: 100.0%,  \t Loss: 0.0336\n",
      "Epoch: 30 [2432/5446 (45%)],\tAccuracy: 100.0%,  \t Loss: 0.0169\n",
      "Epoch: 30 [2560/5446 (47%)],\tAccuracy: 100.0%,  \t Loss: 0.0341\n",
      "Epoch: 30 [2688/5446 (49%)],\tAccuracy: 99.2%,  \t Loss: 0.0584\n",
      "Epoch: 30 [2816/5446 (52%)],\tAccuracy: 100.0%,  \t Loss: 0.0225\n",
      "Epoch: 30 [2944/5446 (54%)],\tAccuracy: 100.0%,  \t Loss: 0.0211\n",
      "Epoch: 30 [3072/5446 (56%)],\tAccuracy: 100.0%,  \t Loss: 0.0730\n",
      "Epoch: 30 [3200/5446 (59%)],\tAccuracy: 100.0%,  \t Loss: 0.0226\n",
      "Epoch: 30 [3328/5446 (61%)],\tAccuracy: 100.0%,  \t Loss: 0.0184\n",
      "Epoch: 30 [3456/5446 (63%)],\tAccuracy: 100.0%,  \t Loss: 0.0299\n",
      "Epoch: 30 [3584/5446 (66%)],\tAccuracy: 100.0%,  \t Loss: 0.0297\n",
      "Epoch: 30 [3712/5446 (68%)],\tAccuracy: 100.0%,  \t Loss: 0.0204\n",
      "Epoch: 30 [3840/5446 (71%)],\tAccuracy: 100.0%,  \t Loss: 0.0237\n",
      "Epoch: 30 [3968/5446 (73%)],\tAccuracy: 100.0%,  \t Loss: 0.0257\n",
      "Epoch: 30 [4096/5446 (75%)],\tAccuracy: 100.0%,  \t Loss: 0.0131\n",
      "Epoch: 30 [4224/5446 (78%)],\tAccuracy: 100.0%,  \t Loss: 0.0355\n",
      "Epoch: 30 [4352/5446 (80%)],\tAccuracy: 100.0%,  \t Loss: 0.0149\n",
      "Epoch: 30 [4480/5446 (82%)],\tAccuracy: 100.0%,  \t Loss: 0.0212\n",
      "Epoch: 30 [4608/5446 (85%)],\tAccuracy: 100.0%,  \t Loss: 0.0173\n",
      "Epoch: 30 [4736/5446 (87%)],\tAccuracy: 100.0%,  \t Loss: 0.0196\n",
      "Epoch: 30 [4864/5446 (89%)],\tAccuracy: 99.2%,  \t Loss: 0.0426\n",
      "Epoch: 30 [4992/5446 (92%)],\tAccuracy: 100.0%,  \t Loss: 0.0369\n",
      "Epoch: 30 [5120/5446 (94%)],\tAccuracy: 99.2%,  \t Loss: 0.0396\n",
      "Epoch: 30 [5248/5446 (96%)],\tAccuracy: 100.0%,  \t Loss: 0.0541\n",
      "Epoch: 30 [5376/5446 (99%)],\tAccuracy: 100.0%,  \t Loss: 0.0287\n",
      "Epoch: 30 [5446/5446 (100%)],\tAccuracy: 98.6%,  \t Loss: 0.0581\n",
      "loss_val: 0.6783510372042656 616\n",
      "acc_val: 589 616\n",
      "Validation ==================================================\n",
      "Avg loss (val): 0.0011\n",
      "Avg acc (val): 0.9562\n",
      "\n",
      "Test:  [128/3929 (3%)],\tAccuracy: 35.2%,  \t Loss: 2.170740\n",
      "Test:  [256/3929 (6%)],\tAccuracy: 43.0%,  \t Loss: 1.485082\n",
      "Test:  [384/3929 (10%)],\tAccuracy: 46.1%,  \t Loss: 1.257426\n",
      "Test:  [512/3929 (13%)],\tAccuracy: 44.9%,  \t Loss: 1.642024\n",
      "Test:  [640/3929 (16%)],\tAccuracy: 50.2%,  \t Loss: 0.770548\n",
      "Test:  [768/3929 (19%)],\tAccuracy: 49.2%,  \t Loss: 1.714892\n",
      "Test:  [896/3929 (23%)],\tAccuracy: 54.8%,  \t Loss: 0.310679\n",
      "Test:  [1024/3929 (26%)],\tAccuracy: 59.7%,  \t Loss: 0.190184\n",
      "Test:  [1152/3929 (29%)],\tAccuracy: 63.6%,  \t Loss: 0.178104\n",
      "Test:  [1280/3929 (32%)],\tAccuracy: 66.5%,  \t Loss: 0.218439\n",
      "Test:  [1408/3929 (35%)],\tAccuracy: 68.8%,  \t Loss: 0.189197\n",
      "Test:  [1536/3929 (39%)],\tAccuracy: 70.4%,  \t Loss: 0.370372\n",
      "Test:  [1664/3929 (42%)],\tAccuracy: 69.9%,  \t Loss: 1.064141\n",
      "Test:  [1792/3929 (45%)],\tAccuracy: 69.0%,  \t Loss: 1.200550\n",
      "Test:  [1920/3929 (48%)],\tAccuracy: 68.7%,  \t Loss: 0.943517\n",
      "Test:  [2048/3929 (52%)],\tAccuracy: 68.5%,  \t Loss: 0.903448\n",
      "Test:  [2176/3929 (55%)],\tAccuracy: 68.8%,  \t Loss: 0.700202\n",
      "Test:  [2304/3929 (58%)],\tAccuracy: 68.8%,  \t Loss: 1.108087\n",
      "Test:  [2432/3929 (61%)],\tAccuracy: 69.8%,  \t Loss: 0.383844\n",
      "Test:  [2560/3929 (65%)],\tAccuracy: 71.2%,  \t Loss: 0.056704\n",
      "Test:  [2688/3929 (68%)],\tAccuracy: 72.3%,  \t Loss: 0.188570\n",
      "Test:  [2816/3929 (71%)],\tAccuracy: 73.3%,  \t Loss: 0.194127\n",
      "Test:  [2944/3929 (74%)],\tAccuracy: 74.3%,  \t Loss: 0.195564\n",
      "Test:  [3072/3929 (77%)],\tAccuracy: 74.6%,  \t Loss: 0.486365\n",
      "Test:  [3200/3929 (81%)],\tAccuracy: 74.9%,  \t Loss: 0.580565\n",
      "Test:  [3328/3929 (84%)],\tAccuracy: 75.2%,  \t Loss: 0.488749\n",
      "Test:  [3456/3929 (87%)],\tAccuracy: 75.4%,  \t Loss: 0.496032\n",
      "Test:  [3584/3929 (90%)],\tAccuracy: 75.9%,  \t Loss: 0.429695\n",
      "Test:  [3712/3929 (94%)],\tAccuracy: 76.4%,  \t Loss: 0.316264\n",
      "Test:  [3840/3929 (97%)],\tAccuracy: 77.0%,  \t Loss: 0.139978\n",
      "Test:  [3929/3929 (100%)],\tAccuracy: 77.3%,  \t Loss: 0.308070\n",
      "77.3\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x144 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stage1 (train,val): 1499 171\n",
      "stage2 (train,val): 3339 379\n",
      "stage3 (train,val): 6870 777\n",
      "test : 2344\n",
      "Epoch: 1 [128/1499 (9%)],\tAccuracy: 14.1%,  \t Loss: 2.9377\n",
      "Epoch: 1 [256/1499 (17%)],\tAccuracy: 21.9%,  \t Loss: 2.9139\n",
      "Epoch: 1 [384/1499 (26%)],\tAccuracy: 36.7%,  \t Loss: 2.7405\n",
      "Epoch: 1 [512/1499 (34%)],\tAccuracy: 51.6%,  \t Loss: 2.4277\n",
      "Epoch: 1 [640/1499 (43%)],\tAccuracy: 48.4%,  \t Loss: 2.2451\n",
      "Epoch: 1 [768/1499 (51%)],\tAccuracy: 56.2%,  \t Loss: 2.2093\n",
      "Epoch: 1 [896/1499 (60%)],\tAccuracy: 64.1%,  \t Loss: 2.0783\n",
      "Epoch: 1 [1024/1499 (68%)],\tAccuracy: 73.4%,  \t Loss: 1.8943\n",
      "Epoch: 1 [1152/1499 (77%)],\tAccuracy: 76.6%,  \t Loss: 1.5940\n",
      "Epoch: 1 [1280/1499 (85%)],\tAccuracy: 82.0%,  \t Loss: 1.4682\n",
      "Epoch: 1 [1408/1499 (94%)],\tAccuracy: 87.5%,  \t Loss: 1.3007\n",
      "Epoch: 1 [1499/1499 (100%)],\tAccuracy: 96.7%,  \t Loss: 0.8525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-381:\n",
      "Traceback (most recent call last):\n",
      "Exception ignored in: <function _releaseLock at 0x7f05595584c0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/logging/__init__.py\", line 227, in _releaseLock\n",
      "    def _releaseLock():\n",
      "KeyboardInterrupt: \n",
      "  File \"/opt/conda/lib/python3.8/multiprocessing/process.py\", line 299, in _bootstrap\n",
      "    util._close_stdin()\n",
      "  File \"/opt/conda/lib/python3.8/multiprocessing/util.py\", line 422, in _close_stdin\n",
      "    sys.stdin = open(fd, closefd=False)\n",
      "  File \"/opt/conda/lib/python3.8/_bootlocale.py\", line 33, in getpreferredencoding\n",
      "    def getpreferredencoding(do_setlocale=True):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 1397312, 1397352, 1397392) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    107\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mEmpty\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-5fee9718039d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;31m##########################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtrain_settings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         test_accuracy = test(\n\u001b[1;32m     48\u001b[0m             \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mused_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtry_check\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/daehee/daehee/DG/SelfReg/codes/utils.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loaders, val_loaders, optimizer, model, lr_scheduler, swa_model, swa_scr, device, epochs, criterion, is_selfreg, is_idcl, SelfReg_criterion)\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1186\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1187\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1001\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfailed_workers\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1002\u001b[0m                 \u001b[0mpids_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m', '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfailed_workers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DataLoader worker (pid(s) {}) exited unexpectedly'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpids_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1004\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmpty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 1397312, 1397352, 1397392) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "save_model_setting(model_settings, used_model, domains, dataset, save_name)\n",
    "set_train = IDCL_setting if is_idcl else classic_setting\n",
    "temp_dict = {\n",
    "    \"device\": device,\n",
    "    \"epochs\": epochs,\n",
    "    \"criterion\": criterion,\n",
    "    \"is_selfreg\": is_selfreg,\n",
    "    \"is_idcl\": is_idcl,\n",
    "}\n",
    "\n",
    "for i in range(1, number_of_tests + 1):\n",
    "    try_check = i\n",
    "\n",
    "    for test_idx in [3, 2, 1, 0]:\n",
    "\n",
    "        ##########################\n",
    "        ####   Setting Train  ####\n",
    "        ##########################\n",
    "\n",
    "        model_sets = [\n",
    "            test_idx,\n",
    "            domains,\n",
    "            batch_size,\n",
    "            is_pretrained,\n",
    "            train_tf,\n",
    "            test_tf,\n",
    "            used_model,\n",
    "            pacs_ver,\n",
    "            used_optimizer,\n",
    "        ]\n",
    "        train_settings, test_loader = set_train(*model_sets)\n",
    "        train_settings.update(temp_dict)\n",
    "\n",
    "        save_dir = save_route(test_idx, domains, dataset, save_name, used_model)\n",
    "\n",
    "        try:\n",
    "            if not os.path.exists(save_dir):\n",
    "                os.makedirs(save_dir)\n",
    "        except:\n",
    "            print(\"Error : Creating directory. \" + save_dir)\n",
    "\n",
    "        ##########################\n",
    "        ####     Training     ####\n",
    "        ##########################\n",
    "\n",
    "        model, losses, accuracies = train(**train_settings)\n",
    "        test_accuracy = test(\n",
    "            device, model, criterion, test_loader, used_model, save_dir, try_check\n",
    "        )\n",
    "\n",
    "        total_result_text_path = os.path.join(save_dir, \"test_total_result.txt\")\n",
    "        with open(total_result_text_path, \"a\") as f:\n",
    "            print(test_accuracy)\n",
    "            f.write(str(test_accuracy) + \"\\n\")\n",
    "\n",
    "        plotting(losses, accuracies, used_model, save_dir, is_pretrained, try_check)\n",
    "#         save_model(model, used_model, save_dir, is_pretrained, try_check)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "499.4px",
    "left": "954px",
    "right": "20px",
    "top": "239px",
    "width": "503px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
